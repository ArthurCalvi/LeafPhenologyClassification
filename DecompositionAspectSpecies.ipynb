{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '/Users/arthurcalvi/Data/species/validation/tiles'\n",
    "import os\n",
    "from datetime import datetime \n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "import rasterio \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.metrics import davies_bouldin_score, cohen_kappa_score, confusion_matrix\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "#read json config and get the new numerous of config\n",
    "import json\n",
    "if not os.path.exists('logs/config.json'):\n",
    "    name_config = 'config_0'\n",
    "    #create a new json file\n",
    "    with open('logs/config.json', 'w') as f:\n",
    "        data = {}\n",
    "        json.dump(data, f)\n",
    "else :\n",
    "    with open('logs/config.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        name_config = list(data.keys())\n",
    "        #Sort \n",
    "        name_config.sort()\n",
    "        name_config = name_config[-1]\n",
    "        numero_config = int(name_config.split('_')[1]) + 1\n",
    "        name_config = f'config_{numero_config}'\n",
    "\n",
    "print(name_config)\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Calculate metrics for classification.\"\"\"\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=[1, 2])\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    oa = (tp + tn) / np.sum(cm)\n",
    "    kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
    "    return oa, kappa, tp, fp, tn, fn\n",
    "\n",
    "#remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for folder in tqdm(os.listdir(dir_)):\n",
    "\n",
    "    path = os.path.join(dir_, folder)\n",
    "\n",
    "    if folder.endswith('training') or folder.__contains__('.DS_Store') or folder.__contains__('.txt'):\n",
    "        continue\n",
    "\n",
    "    n_tuile = folder.split('_')[1]\n",
    "\n",
    "    path_features = os.path.join(path, 'features')\n",
    "    #check if r_APO.tif exists\n",
    "    path = os.path.join(dir_, folder)\n",
    "\n",
    "    dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "    dates.sort() \n",
    "    rgb = load_folder(os.path.join(path, 'rgb'))\n",
    "    # forest_mask = rasterio.open(os.path.join(path,'tree_map', 'tree_class_map.tif')).read(1).astype(bool)\n",
    "    chm = rasterio.open(os.path.join(path,'tree_map', 'CHM2020.tif')).read(1)\n",
    "    forest_mask = (chm > 250).astype(bool) # 2.5m threshold \n",
    "\n",
    "    #weights \n",
    "    slope_map = calculate_slope_with_dates(rgb[:,0], dates, len(rgb[:,0])/2, len(rgb[:,0])) / 100 # 100 is the max slope value\n",
    "    weights = (1 - abs(slope_map.ravel())).clip(0, 1)\n",
    "    updated_weights = weights \n",
    "\n",
    "    #features\n",
    "    try: \n",
    "        r_APO = rasterio.open(os.path.join(path_features, 'r_APO.tif')).read()\n",
    "        amplitude_map_r, phase_map_r, offset_map_r = r_APO[0], r_APO[1], r_APO[2]\n",
    "\n",
    "        crswir_APO = rasterio.open(os.path.join(path_features, 'crswir_APO.tif')).read()\n",
    "        amplitude_map_crswir, phase_map_crswir, offset_map_crswir = crswir_APO[0], crswir_APO[1], crswir_APO[2]\n",
    "\n",
    "        dem = rasterio.open(os.path.join(path_features, 'elevation_aspect.tif')).read()\n",
    "        elevation, aspect = dem[0], dem[1]\n",
    "\n",
    "        # Define features\n",
    "        f1 = amplitude_map_r\n",
    "        f2 = np.cos(phase_map_r)\n",
    "        f3 = np.sin(phase_map_r)\n",
    "        f4 = offset_map_r\n",
    "        f5 = amplitude_map_crswir\n",
    "        f6= offset_map_crswir\n",
    "        f7 = elevation \n",
    "        aspect_radians = np.radians(aspect)\n",
    "        aspect_radians[ np.isnan(aspect_radians) ] = 0\n",
    "        f8 = np.cos(aspect_radians)\n",
    "        f9 = np.sin(aspect_radians)\n",
    "\n",
    "        features = np.stack((f1.ravel(), f2.ravel(), f3.ravel(), f4.ravel(), f5.ravel(), f6.ravel(), f7.ravel(), f8.ravel(), f9.ravel()), axis=-1)\n",
    "        filtered_features = features[forest_mask.ravel()]\n",
    "        filtered_weights = weights[forest_mask.ravel()]\n",
    "\n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(filtered_features)\n",
    "\n",
    "        # Determine the optimal number of clusters using the Elbow Method with MiniBatchKMeans\n",
    "        # wcss = []  # Within-cluster sum of squares\n",
    "        davies_bouldin_indices = []  # Davies-Bouldin index\n",
    "        K = range(3, 11)  # You can adjust the range based on your data\n",
    "\n",
    "        for k in K:\n",
    "            minibatch_kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "            clusters = minibatch_kmeans.fit_predict(features_scaled, sample_weight=filtered_weights)\n",
    "            # wcss.append(minibatch_kmeans.inertia_)\n",
    "            davies_bouldin_indices.append(davies_bouldin_score(features_scaled, clusters))\n",
    "\n",
    "        # Determine the optimal number of clusters by finding the elbow point\n",
    "        # optimal_k2 = K[np.argmax(np.diff(wcss, 2)) + 1]  # This uses the second derivative to find the elbow point\n",
    "        optimal_k = K[np.argmin(davies_bouldin_indices)]\n",
    "        # print(f\"The optimal number of clusters is (wcss): {optimal_k2}\")\n",
    "        print(f\"The optimal number of clusters is (davies bouldin): {optimal_k}\")\n",
    "\n",
    "        # Apply MiniBatchKMeans with the optimal number of clusters\n",
    "        minibatch_kmeans = MiniBatchKMeans(n_clusters=optimal_k, random_state=42)\n",
    "        clusters = minibatch_kmeans.fit_predict(features_scaled, sample_weight=filtered_weights)\n",
    "\n",
    "        # Reshape clusters to original shape\n",
    "        cluster_map = np.full(f1.shape, -1)\n",
    "        cluster_map.ravel()[forest_mask.ravel()] = clusters\n",
    "\n",
    "        # Create the figure with two columns, adjusting the width ratios\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "        # Plot the Davies-Bouldin Index for the Elbow Method\n",
    "        ax1.plot(K, davies_bouldin_indices, 'bo-', label='Davies-Bouldin Index')\n",
    "        ax1.set_xlabel('Number of clusters')\n",
    "        ax1.set_ylabel('Davies-Bouldin Index')\n",
    "        ax1.set_title('Davies-Bouldin Index For Optimal Number of Clusters')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "        ax1.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "        ax1.text(optimal_k, min(davies_bouldin_indices), f' k={optimal_k}', color='r', verticalalignment='bottom')\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "\n",
    "        # Create a segmented colormap for clusters\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, optimal_k+1))\n",
    "        segmented_cmap = ListedColormap(colors)\n",
    "\n",
    "        # Plot the KMeans Clustering of Features\n",
    "        print(np.unique(cluster_map))\n",
    "        im = ax2.imshow(cluster_map, cmap=segmented_cmap)\n",
    "        cbar = plt.colorbar(im, ax=ax2, orientation='vertical', shrink=0.5, ticks=range(optimal_k))\n",
    "        cbar.set_label('Cluster')\n",
    "        cbar.set_ticks(np.arange(optimal_k) - 0.5)\n",
    "        cbar.set_ticklabels([f'{i+1}' for i in range(optimal_k)])\n",
    "        ax2.set_title('KMeans Clustering of Features')\n",
    "        ax2.axis('off')\n",
    "\n",
    "        # Adjust layout for a clean look\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(f'images/supplementarymaterials1_figure2_kmeans_tuile{n_tuile}.png', dpi=300)\n",
    "\n",
    "\n",
    "        # Flatten and mask the values based on the forest mask\n",
    "        values = amplitude_map_crswir.ravel()[forest_mask.ravel()]\n",
    "\n",
    "        # Calculate the centroids of each cluster\n",
    "        centroids = np.array([np.nanmean(values[clusters == i]) for i in range(optimal_k)]).reshape(-1, 1)\n",
    "\n",
    "        # Perform hierarchical clustering on the centroids\n",
    "        Z = linkage(centroids, method='ward')\n",
    "\n",
    "        # Choose a threshold to form flat clusters from the dendrogram\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 2]})\n",
    "        dendro = dendrogram(Z, labels=[f'{i+1}' for i in range(optimal_k)], ax=ax1, color_threshold=Z[-2, 2])\n",
    "        # max_d = np.max(dendro['dcoord']) * 0.7  # This value can be adjusted based on the dendrogram\n",
    "        # Choose a threshold to form exactly two flat clusters from the dendrogram\n",
    "        # Choose the number of clusters directly\n",
    "        max_d = Z[-2, 2]\n",
    "        # Form flat clusters based on the chosen number of clusters\n",
    "        flat_clusters = fcluster(Z, max_d, criterion='distance')\n",
    "\n",
    "        # Initialize group labels\n",
    "        group1, group2 = 1, 2\n",
    "\n",
    "        # Map flat clusters back to the original KMeans clusters\n",
    "        cluster_mapping = {i: flat_clusters[i] for i in range(optimal_k)}\n",
    "\n",
    "        # Create a new classification map based on the hierarchical clustering of centroids\n",
    "        final_classification_map = np.full(cluster_map.shape, -1)\n",
    "        for original_cluster, new_cluster in cluster_mapping.items():\n",
    "            final_classification_map[cluster_map == original_cluster] = new_cluster\n",
    "\n",
    "        # Collect CRSWIR amplitude values for each group\n",
    "        group_amplitudes = {group: [] for group in [group1, group2]}\n",
    "        for group in [group1, group2]:\n",
    "            group_clusters = [i for i in range(optimal_k) if flat_clusters[i] == group]\n",
    "            group_mask = np.isin(cluster_map, group_clusters)\n",
    "            group_amplitudes[group] = amplitude_map_crswir[group_mask]\n",
    "\n",
    "        # Compare the CRSWIR amplitudes between groups\n",
    "        group1_amplitudes = np.array(group_amplitudes[group1])\n",
    "        group2_amplitudes = np.array(group_amplitudes[group2])\n",
    "\n",
    "        # Perform a t-test to compare the means of the two groups\n",
    "        t_stat, p_value = ttest_ind(group1_amplitudes, group2_amplitudes, equal_var=False)\n",
    "\n",
    "        # Determine which group is deciduous based on the t-test results\n",
    "        mean_group1 = np.mean(group1_amplitudes)\n",
    "        mean_group2 = np.mean(group2_amplitudes)\n",
    "\n",
    "        print(f\"Group {group1} - Mean amplitude CRSWIR: {mean_group1}\")\n",
    "        print(f\"Group {group2} - Mean amplitude CRSWIR: {mean_group2}\")\n",
    "        print(f\"T-test p-value: {p_value}\")\n",
    "\n",
    "        # Set significance level\n",
    "        alpha = 0.05\n",
    "\n",
    "        # Decision based on p-value\n",
    "        if p_value < alpha and (mean_group1 >= 1.75 * mean_group2 or mean_group2 >= 1.75 * mean_group1):\n",
    "            print(f\"The hypothesis that one group has twice the amplitude of the other is not rejected.\")\n",
    "            if mean_group1 > mean_group2:\n",
    "                deciduous_group = [group1]\n",
    "                evergreen_group = [group2]\n",
    "            else:\n",
    "                deciduous_group = [group2]\n",
    "                evergreen_group = [group1]\n",
    "            \n",
    "        else:\n",
    "            # If the hypothesis is not rejected, use the threshold for classification\n",
    "            deciduous_group = []\n",
    "            evergreen_group = []\n",
    "            if mean_group1 > 2000:\n",
    "                deciduous_group.append(group1)\n",
    "            else:\n",
    "                evergreen_group.append(group1)\n",
    "            if mean_group2 > 2000:\n",
    "                deciduous_group.append(group2)\n",
    "            else:\n",
    "                evergreen_group.append(group2)\n",
    "            print(f\"The hypothesis that the two groups have significantly different amplitudes is rejected.\")\n",
    "\n",
    "        print(f\"Deciduous groups: {deciduous_group}\")\n",
    "        print(f\"Evergreen groups: {evergreen_group}\")\n",
    "\n",
    "        # Create a final classification map based on these groupings\n",
    "        final_dec_ever_classification_map = np.full(cluster_map.shape, 0)\n",
    "        for group in deciduous_group:\n",
    "            group_clusters = [i for i in range(optimal_k) if flat_clusters[i] == group]\n",
    "            final_dec_ever_classification_map[np.isin(cluster_map, group_clusters)] = 1  # Deciduous\n",
    "        for group in evergreen_group:\n",
    "            group_clusters = [i for i in range(optimal_k) if flat_clusters[i] == group]\n",
    "            final_dec_ever_classification_map[np.isin(cluster_map, group_clusters)] = 2  # Evergreen\n",
    "\n",
    "        # Create a custom colormap for the classification\n",
    "        cmap = ListedColormap(['lightgray', 'brown', 'green'])\n",
    "\n",
    "        # Plot the final classification map for deciduous and evergreen trees\n",
    "        # Create the figure with two columns, adjusting the width ratios\n",
    "\n",
    "        # Plot the dendrogram\n",
    "        ax1.set_title('Hierarchical Clustering Dendrogram of KMeans Centroids')\n",
    "        ax1.set_xlabel('Cluster')\n",
    "        ax1.set_ylabel('Distance')\n",
    "        ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "        # Plot the final classification map for deciduous and evergreen trees\n",
    "        im = ax2.imshow(final_dec_ever_classification_map, cmap=cmap)\n",
    "        cbar = plt.colorbar(im, ax=ax2, ticks=[-1, 0, 1], orientation='vertical', pad=0.1, shrink=0.5)\n",
    "        cbar.set_label('Tree Type')\n",
    "        cbar.set_ticklabels(['No forest', 'Deciduous', 'Evergreen'])\n",
    "        ax2.set_title('Classification Map')\n",
    "        ax2.axis('off')\n",
    "\n",
    "        # Adjust layout for a clean look\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Save the figure\n",
    "        fig.savefig(f'supplementarymaterials1_figure3_dendrogram-classification_tuile{n_tuile}.png', dpi=300)\n",
    "\n",
    "        # save final classification as tif. in result folder\n",
    "        os.makedirs(os.path.join(path, 'results_classification'), exist_ok=True)\n",
    "        ref = rasterio.open(os.path.join(path, 'rgb', os.listdir(os.path.join(path, 'rgb'))[0]))\n",
    "        profile = ref.profile\n",
    "        profile.update(count=1, dtype=rasterio.uint8)\n",
    "        with rasterio.open(os.path.join(path, 'results_classification', f'{name_config}.tif'), 'w', **profile) as dst:\n",
    "            dst.write(final_dec_ever_classification_map.astype(rasterio.uint8), 1)\n",
    "    \n",
    "        #references \n",
    "        path_reference = os.path.join(path, 'reference_species')\n",
    "        tif = [x for x in os.listdir(path_reference) if x.endswith('.tif')]\n",
    "        reference = rasterio.open(os.path.join(path_reference, tif[0])).read()\n",
    "        species, genus, phen, year, source = reference[0], reference[1], reference[2], reference[3], reference[4] \n",
    "        # Filter out null data\n",
    "        valid_mask = species != 0\n",
    "\n",
    "        # Calculate metrics\n",
    "        true_labels = phen[forest_mask & valid_mask]\n",
    "        predicted_labels = final_dec_ever_classification_map[forest_mask & valid_mask]\n",
    "\n",
    "        oa, kappa, tp, fp, tn, fn = calculate_metrics(true_labels.ravel(), predicted_labels.ravel())\n",
    "\n",
    "        # Store results\n",
    "        r = {\n",
    "            'tile': folder,\n",
    "            'OA': oa,\n",
    "            'Kappa': kappa,\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'TN': tn,\n",
    "            'FN': fn\n",
    "        }\n",
    "        print(r)\n",
    "        results.append(r)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "#compute OA_ALL, KAPPA_ALL, TP_ALL, FP_ALL, TN_ALL, FN_ALL FROM RESULTS\n",
    "\n",
    "KAPPA_ALL = sum([r['Kappa'] for r in results if not np.isnan(r['Kappa'])]) / len(results)\n",
    "TP_ALL = sum([r['TP'] for r in results])\n",
    "FP_ALL = sum([r['FP'] for r in results])\n",
    "TN_ALL = sum([r['TN'] for r in results])\n",
    "FN_ALL = sum([r['FN'] for r in results])\n",
    "OA_ALL = (TP_ALL + TN_ALL) / (TP_ALL + FP_ALL + TN_ALL + FN_ALL)\n",
    "\n",
    "config = {name_config: {'n_clusters':'davies-bouldin', \n",
    "                      'features': ['amplitude_map_r', 'phase_map_r', 'offset_map_r', 'amplitude_map_crswir', 'offset_map_crswir', 'elevation', 'aspect'],\n",
    "                      '2nd step': {'method': 'hierarchical', 'threshold': 'distance', 'criterion': 'distance', 'groups': '2'},\n",
    "                        '3rd step': {'method': 't-test', 'threshold': '0.05', 'amplitude_threshold': '2000', 'features': 'amplitude_map_crswir'},\n",
    "                        'results': {\"OA\": OA_ALL, \"KAPPA\": KAPPA_ALL, \"TP\": TP_ALL, \"FP\": FP_ALL, \"TN\": TN_ALL, \"FN\": FN_ALL} \n",
    "},} \n",
    "\n",
    "print(config)\n",
    "\n",
    "#add config to a existing json called config.json that contain every config\n",
    "import json\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "with open('logs/config.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    data.update(config)\n",
    "with open('logs/config.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open(f'logs/results_{name_config}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On All tiles at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davies Bouldin with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data_from_tile(path: str) -> tuple:\n",
    "    \"\"\"Load and preprocess data from a tile.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the tile directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Preprocessed features, weights, forest mask, species data, and shape of the original tile.\n",
    "    \"\"\"\n",
    "    dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "    dates.sort()\n",
    "    rgb = load_folder(os.path.join(path, 'rgb'))\n",
    "    chm = rasterio.open(os.path.join(path, 'tree_map', 'CHM2020.tif')).read(1)\n",
    "    forest_mask = (chm > 250).astype(bool)\n",
    "    slope_map = calculate_slope_with_dates(rgb[:, 0], dates, len(rgb[:, 0]) / 2, len(rgb[:, 0])) / 100\n",
    "    weights = (1 - abs(slope_map.ravel())).clip(0, 1)\n",
    "\n",
    "    path_features = os.path.join(path, 'features')\n",
    "    r_APO = rasterio.open(os.path.join(path_features, 'r_APO.tif')).read()\n",
    "    amplitude_map_r, phase_map_r, offset_map_r = r_APO[0], r_APO[1], r_APO[2]\n",
    "    crswir_APO = rasterio.open(os.path.join(path_features, 'crswir_APO.tif')).read()\n",
    "    amplitude_map_crswir, phase_map_crswir, offset_map_crswir = crswir_APO[0], crswir_APO[1], crswir_APO[2]\n",
    "    dem = rasterio.open(os.path.join(path_features, 'elevation_aspect.tif')).read()\n",
    "    elevation, aspect = dem[0], dem[1]\n",
    "\n",
    "    f1 = amplitude_map_r\n",
    "    f2 = np.cos(phase_map_r)\n",
    "    f3 = np.sin(phase_map_r)\n",
    "    f4 = offset_map_r\n",
    "    f5 = amplitude_map_crswir\n",
    "    f6 = offset_map_crswir\n",
    "    f7 = elevation\n",
    "    aspect_radians = np.radians(aspect)\n",
    "    aspect_radians[np.isnan(aspect_radians)] = 0\n",
    "    f8 = np.cos(aspect_radians)\n",
    "    f9 = np.sin(aspect_radians)\n",
    "\n",
    "    features = np.stack((f1.ravel(), f2.ravel(), f3.ravel(), f4.ravel(), f5.ravel(), f6.ravel(), f7.ravel(), f8.ravel(), f9.ravel()), axis=-1)\n",
    "    filtered_features = features[forest_mask.ravel()]\n",
    "    filtered_weights = weights[forest_mask.ravel()]\n",
    "\n",
    "    # Load reference data\n",
    "    path_reference = os.path.join(path, 'reference_species')\n",
    "    tif = [x for x in os.listdir(path_reference) if x.endswith('.tif')]\n",
    "    reference = rasterio.open(os.path.join(path_reference, tif[0])).read()\n",
    "    # species = reference[0]\n",
    "    # filtered_species = species[forest_mask]\n",
    "    genus = reference[1]\n",
    "    filtered_genus = genus[forest_mask]\n",
    "\n",
    "    return filtered_features, filtered_weights, forest_mask, filtered_genus, f1.shape\n",
    "\n",
    "# Initialize variables for stacking\n",
    "all_features = []\n",
    "all_weights = []\n",
    "all_ref = []\n",
    "tile_shapes = []\n",
    "\n",
    "# Load data from all tiles\n",
    "print('Loading data from all tiles')\n",
    "for folder in tqdm(os.listdir(dir_)):\n",
    "    path = os.path.join(dir_, folder)\n",
    "    if folder.endswith('training') or folder.__contains__('.DS_Store') or folder.__contains__('.txt'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        filtered_features, filtered_weights, forest_mask, filtered_ref, tile_shape = load_data_from_tile(path)\n",
    "        all_features.append(filtered_features)\n",
    "        all_weights.append(filtered_weights)\n",
    "        all_ref.append(filtered_ref)\n",
    "        tile_shapes.append((path, forest_mask, tile_shape))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {folder}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Stack all features, weights, and species\n",
    "all_features_stacked = np.vstack(all_features)\n",
    "all_weights_stacked = np.concatenate(all_weights)\n",
    "all_ref_stacked = np.concatenate(all_ref)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(all_features_stacked)\n",
    "\n",
    "# Determine the optimal number of clusters using Davies-Bouldin index\n",
    "davies_bouldin_indices = []\n",
    "wcss = []  # Within-cluster sum of squares\n",
    "K = range(2, 25)  # Range of number of clusters\n",
    "\n",
    "print('Determining the optimal number of clusters using Davies-Bouldin index')\n",
    "for k in tqdm(K):\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "    clusters = minibatch_kmeans.fit_predict(features_scaled, sample_weight=all_weights_stacked)\n",
    "    wcss.append(minibatch_kmeans.inertia_)\n",
    "    davies_bouldin_indices.append(davies_bouldin_score(features_scaled, clusters))\n",
    "\n",
    "optimal_k = K[np.argmin(davies_bouldin_indices)]\n",
    "optimal_k2 = K[np.argmax(np.diff(wcss, 2)) + 1]\n",
    "print(f\"The optimal number of clusters is (Davies-Bouldin): {optimal_k}\")\n",
    "print(f\"The optimal number of clusters is (Elbow Method): {optimal_k2}\")\n",
    "\n",
    "# Plot Davies-Bouldin index and WCSS\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Plot the Davies-Bouldin Index\n",
    "ax1.plot(K, davies_bouldin_indices, 'bo-', label='Davies-Bouldin Index')\n",
    "ax1.set_xlabel('Number of clusters')\n",
    "ax1.set_ylabel('Davies-Bouldin Index')\n",
    "ax1.set_title('Davies-Bouldin Index For Optimal Number of Clusters')\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax1.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "ax1.text(optimal_k, min(davies_bouldin_indices), f' k={optimal_k}', color='r', verticalalignment='bottom')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(K, wcss, 'go-', label='WCSS')\n",
    "ax2.set_ylabel('WCSS')\n",
    "ax2.legend()\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax2.axvline(x=optimal_k2, color='g', linestyle='--')\n",
    "ax2.text(optimal_k2, min(wcss), f' k={optimal_k2}', color='g', verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply MiniBatchKMeans with the optimal number of clusters\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = minibatch_kmeans.fit_predict(features_scaled, sample_weight=all_weights_stacked)\n",
    "\n",
    "# Reconstruct cluster maps for each tile\n",
    "cluster_maps = []\n",
    "index = 0\n",
    "for path, forest_mask, tile_shape in tile_shapes:\n",
    "    cluster_map = np.full(tile_shape, -1)\n",
    "    n_points = forest_mask.ravel().sum()\n",
    "    cluster_map.ravel()[forest_mask.ravel()] = clusters[index:index + n_points]\n",
    "    index += n_points\n",
    "    cluster_maps.append((path, cluster_map))\n",
    "\n",
    "# Save or process cluster maps\n",
    "# for path, cluster_map in cluster_maps:\n",
    "#     output_path = os.path.join(path, 'cluster_map.tif')\n",
    "#     with rasterio.open(output_path, 'w', driver='GTiff', height=cluster_map.shape[0], width=cluster_map.shape[1], count=1, dtype=cluster_map.dtype) as dst:\n",
    "#         dst.write(cluster_map, 1)\n",
    "\n",
    "# Plot the relationship between clusters, aspect, and species\n",
    "aspect = all_features_stacked[:, 7]\n",
    "valid_mask = (all_ref_stacked != 0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(aspect[valid_mask], all_ref_stacked[valid_mask], c=clusters[valid_mask], cmap='tab20', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel('Aspect (radians)')\n",
    "plt.ylabel('Species')\n",
    "plt.title('Clusters in the Aspect-Genus Space')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(\"Clustering completed and cluster maps saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the genus mapping\n",
    "genus_mapping = {\n",
    "    1: 'oak', 2: 'fir', 3: 'pine', 4: 'douglas', 5: 'chestnut',\n",
    "    6: 'spruce', 7: 'larch', 8: 'poplar', 9: 'ash', 10: 'beech',\n",
    "    11: 'alder', 12: 'birch', 13: 'hornbeam', 14: 'locusts'\n",
    "}\n",
    "\n",
    "# Categorize aspect into directions\n",
    "def categorize_aspect(aspect: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Categorize aspect into cardinal and intercardinal directions.\n",
    "\n",
    "    Args:\n",
    "        aspect (np.ndarray): Aspect values between -1 and 1.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Aspect categories ('north', 'north-east', 'east', 'south-east', 'south', 'south-west', 'west', 'north-west').\n",
    "    \"\"\"\n",
    "    directions = np.empty(aspect.shape, dtype='<U10')\n",
    "    directions[(aspect >= -1) & (aspect < -0.75)] = 'north'\n",
    "    directions[(aspect >= -0.75) & (aspect < -0.5)] = 'north-east'\n",
    "    directions[(aspect >= -0.5) & (aspect < -0.25)] = 'east'\n",
    "    directions[(aspect >= -0.25) & (aspect < 0)] = 'south-east'\n",
    "    directions[(aspect >= 0) & (aspect < 0.25)] = 'south'\n",
    "    directions[(aspect >= 0.25) & (aspect < 0.5)] = 'south-west'\n",
    "    directions[(aspect >= 0.5) & (aspect < 0.75)] = 'west'\n",
    "    directions[(aspect >= 0.75) & (aspect <= 1)] = 'north-west'\n",
    "    return directions\n",
    "\n",
    "\n",
    "# Filter out null data\n",
    "valid_mask = (all_ref_stacked != 0)\n",
    "\n",
    "# Convert genus index to names\n",
    "genus = np.vectorize(genus_mapping.get)(all_ref_stacked)\n",
    "\n",
    "# Categorize aspect\n",
    "aspect_directions = categorize_aspect(all_features_stacked[valid_mask, 7])\n",
    "\n",
    "# Plot the relationship between clusters, aspect directions, and genus\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(aspect_directions, genus[valid_mask], c=clusters[valid_mask], cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel('Aspect Direction')\n",
    "plt.ylabel('Genus')\n",
    "plt.title('Clusters in the Aspect Direction-Genus Space')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davies bouldin with aspect and genus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_ = '/Users/arthurcalvi/Data/species/validation/tiles'\n",
    "\n",
    "# Remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data_from_tile(path: str) -> tuple:\n",
    "    \"\"\"Load and preprocess data from a tile.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the tile directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Preprocessed features, weights, forest mask, species data, and shape of the original tile.\n",
    "    \"\"\"\n",
    "    dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "    dates.sort()\n",
    "    rgb = load_folder(os.path.join(path, 'rgb'))\n",
    "    chm = rasterio.open(os.path.join(path, 'tree_map', 'CHM2020.tif')).read(1)\n",
    "    forest_mask = (chm > 250).astype(bool)\n",
    "    slope_map = calculate_slope_with_dates(rgb[:, 0], dates, len(rgb[:, 0]) / 2, len(rgb[:, 0])) / 100\n",
    "    weights = (1 - abs(slope_map.ravel())).clip(0, 1)\n",
    "\n",
    "    path_features = os.path.join(path, 'features')\n",
    "    r_APO = rasterio.open(os.path.join(path_features, 'r_APO.tif')).read()\n",
    "    amplitude_map_r, phase_map_r, offset_map_r = r_APO[0], r_APO[1], r_APO[2]\n",
    "    crswir_APO = rasterio.open(os.path.join(path_features, 'crswir_APO.tif')).read()\n",
    "    amplitude_map_crswir, phase_map_crswir, offset_map_crswir = crswir_APO[0], crswir_APO[1], crswir_APO[2]\n",
    "    dem = rasterio.open(os.path.join(path_features, 'elevation_aspect.tif')).read()\n",
    "    elevation, aspect = dem[0], dem[1]\n",
    "\n",
    "    f1 = amplitude_map_r\n",
    "    f2 = np.cos(phase_map_r)\n",
    "    f3 = np.sin(phase_map_r)\n",
    "    f4 = offset_map_r\n",
    "    f5 = amplitude_map_crswir\n",
    "    f6 = offset_map_crswir\n",
    "    f7 = elevation\n",
    "    aspect_radians = np.radians(aspect)\n",
    "    aspect_radians[np.isnan(aspect_radians)] = 0\n",
    "    f8 = np.cos(aspect_radians)\n",
    "    f9 = np.sin(aspect_radians)\n",
    "\n",
    "    features = np.stack((f1.ravel(), f2.ravel(), f3.ravel(), f4.ravel(), f5.ravel(), f6.ravel(), f7.ravel(), f8.ravel(), f9.ravel()), axis=-1)\n",
    "    filtered_features = features[forest_mask.ravel()]\n",
    "    filtered_weights = weights[forest_mask.ravel()]\n",
    "\n",
    "    # Load reference data\n",
    "    path_reference = os.path.join(path, 'reference_species')\n",
    "    tif = [x for x in os.listdir(path_reference) if x.endswith('.tif')]\n",
    "    reference = rasterio.open(os.path.join(path_reference, tif[0])).read()\n",
    "    genus = reference[1]\n",
    "    filtered_genus = genus[forest_mask]\n",
    "\n",
    "    return filtered_features, filtered_weights, forest_mask, filtered_genus, f1.shape\n",
    "\n",
    "# Initialize variables for stacking\n",
    "all_features = []\n",
    "all_weights = []\n",
    "all_ref = []\n",
    "tile_shapes = []\n",
    "\n",
    "# Load data from all tiles\n",
    "print('Loading data from all tiles')\n",
    "for folder in tqdm(os.listdir(dir_)):\n",
    "    path = os.path.join(dir_, folder)\n",
    "    if folder.endswith('training') or folder.__contains__('.DS_Store') or folder.__contains__('.txt'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        filtered_features, filtered_weights, forest_mask, filtered_ref, tile_shape = load_data_from_tile(path)\n",
    "        all_features.append(filtered_features)\n",
    "        all_weights.append(filtered_weights)\n",
    "        all_ref.append(filtered_ref)\n",
    "        tile_shapes.append((path, forest_mask, tile_shape))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {folder}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Stack all features, weights, and species\n",
    "all_features_stacked = np.vstack(all_features)\n",
    "all_weights_stacked = np.concatenate(all_weights)\n",
    "all_ref_stacked = np.concatenate(all_ref)\n",
    "\n",
    "# Extract aspect and genus for clustering\n",
    "aspect = all_features_stacked[:, 7]  # Aspect\n",
    "genus = all_ref_stacked  # Genus\n",
    "valid_mask = (genus != 0)  # Mask to filter out invalid data\n",
    "\n",
    "# Prepare data for clustering\n",
    "aspect_genus_data = np.stack((aspect, genus), axis=-1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "aspect_genus_scaled = scaler.fit_transform(aspect_genus_data)\n",
    "\n",
    "# Determine the optimal number of clusters using Davies-Bouldin index\n",
    "davies_bouldin_indices = []\n",
    "wcss = []  # Within-cluster sum of squares\n",
    "K = range(2, 25)  # Range of number of clusters\n",
    "\n",
    "print('Determining the optimal number of clusters using Davies-Bouldin index')\n",
    "for k in tqdm(K):\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "    clusters = minibatch_kmeans.fit_predict(aspect_genus_scaled, sample_weight=all_weights_stacked)\n",
    "    wcss.append(minibatch_kmeans.inertia_)\n",
    "    davies_bouldin_indices.append(davies_bouldin_score(aspect_genus_scaled, clusters))\n",
    "\n",
    "optimal_k = K[np.argmin(davies_bouldin_indices)]\n",
    "optimal_k2 = K[np.argmax(np.diff(wcss, 2)) + 1]\n",
    "print(f\"The optimal number of clusters is (Davies-Bouldin): {optimal_k}\")\n",
    "print(f\"The optimal number of clusters is (Elbow Method): {optimal_k2}\")\n",
    "\n",
    "# Plot Davies-Bouldin index and WCSS\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Plot the Davies-Bouldin Index\n",
    "ax1.plot(K, davies_bouldin_indices, 'bo-', label='Davies-Bouldin Index')\n",
    "ax1.set_xlabel('Number of clusters')\n",
    "ax1.set_ylabel('Davies-Bouldin Index')\n",
    "ax1.set_title('Davies-Bouldin Index For Optimal Number of Clusters')\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax1.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "ax1.text(optimal_k, min(davies_bouldin_indices), f' k={optimal_k}', color='r', verticalalignment='bottom')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(K, wcss, 'go-', label='WCSS')\n",
    "ax2.set_ylabel('WCSS')\n",
    "ax2.legend()\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax2.axvline(x=optimal_k2, color='g', linestyle='--')\n",
    "ax2.text(optimal_k2, min(wcss), f' k={optimal_k2}', color='g', verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply MiniBatchKMeans with the optimal number of clusters\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = minibatch_kmeans.fit_predict(aspect_genus_scaled, sample_weight=all_weights_stacked)\n",
    "\n",
    "# Reconstruct cluster maps for each tile\n",
    "cluster_maps = []\n",
    "index = 0\n",
    "for path, forest_mask, tile_shape in tile_shapes:\n",
    "    cluster_map = np.full(tile_shape, -1)\n",
    "    n_points = forest_mask.ravel().sum()\n",
    "    cluster_map[forest_mask] = clusters[index:index + n_points]\n",
    "    index += n_points\n",
    "    cluster_maps.append((path, cluster_map))\n",
    "\n",
    "# Save or process cluster maps\n",
    "# for path, cluster_map in cluster_maps:\n",
    "#     output_path = os.path.join(path, 'cluster_map.tif')\n",
    "#     with rasterio.open(output_path, 'w', driver='GTiff', height=cluster_map.shape[0], width=cluster_map.shape[1], count=1, dtype=cluster_map.dtype) as dst:\n",
    "#         dst.write(cluster_map, 1)\n",
    "\n",
    "# Plot the relationship between clusters, aspect, and species\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(aspect[valid_mask], genus[valid_mask], c=clusters[valid_mask], cmap='tab20', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel('Aspect (radians)')\n",
    "plt.ylabel('Species')\n",
    "plt.title('Clusters in the Aspect-Genus Space')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(\"Clustering completed and cluster maps saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the genus mapping\n",
    "genus_mapping = {\n",
    "    1: 'oak', 2: 'fir', 3: 'pine', 4: 'douglas', 5: 'chestnut',\n",
    "    6: 'spruce', 7: 'larch', 8: 'poplar', 9: 'ash', 10: 'beech',\n",
    "    11: 'alder', 12: 'birch', 13: 'hornbeam', 14: 'locusts'\n",
    "}\n",
    "\n",
    "# Define aspect direction labels for tick marks\n",
    "direction_labels = {\n",
    "    -1: 'N', -0.75: 'NW', -0.5: 'W', -0.25: 'SW', \n",
    "    0: 'S', 0.25: 'SE', 0.5: 'E', 0.75: 'NE', 1: 'N'\n",
    "}\n",
    "\n",
    "# Plot the relationship between clusters, aspect, and genus\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(aspect[valid_mask], [genus_mapping.get(g, 'Unknown') for g in genus[valid_mask]], c=clusters[valid_mask], cmap='tab20', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel('Aspect')\n",
    "plt.ylabel('Genus')\n",
    "\n",
    "# Set custom tick labels for aspect\n",
    "plt.xticks(ticks=list(direction_labels.keys()), labels=list(direction_labels.values()))\n",
    "\n",
    "plt.title('Clusters in the Aspect-Genus Space')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(\"Clustering completed and cluster maps saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kayrros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
