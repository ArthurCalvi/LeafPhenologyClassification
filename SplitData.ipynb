{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data_from_tile(path: str, config: str) -> dict:\n",
    "    tile_id = os.path.basename(path).split('_')[1]\n",
    "    dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "    dates.sort()\n",
    "    rgb = load_folder(os.path.join(path, 'rgb'))\n",
    "    chm = rasterio.open(os.path.join(path, 'tree_map', 'CHM2020.tif')).read(1)\n",
    "    forest_mask = (chm > 250).astype(bool)\n",
    "    slope_map = calculate_slope_with_dates(rgb[:, 0], dates, len(rgb[:, 0]) / 2, len(rgb[:, 0])) / 100\n",
    "    weights = (1 - abs(slope_map.ravel())).clip(0, 1)\n",
    "\n",
    "    path_features = os.path.join(path, 'features')\n",
    "    r_APO = rasterio.open(os.path.join(path_features, f'APO_R_{config}.tif')).read()\n",
    "    amplitude_map_r, phase_map_r, offset_map_r = r_APO[0], r_APO[1], r_APO[2]\n",
    "    g_APO = rasterio.open(os.path.join(path_features, f'APO_G_{config}.tif')).read()\n",
    "    amplitude_map_g, phase_map_g, offset_map_g = g_APO[0], g_APO[1], g_APO[2]\n",
    "    b_APO = rasterio.open(os.path.join(path_features, f'APO_B_{config}.tif')).read()\n",
    "    amplitude_map_b, phase_map_b, offset_map_b = b_APO[0], b_APO[1], b_APO[2]\n",
    "    crswir_APO = rasterio.open(os.path.join(path_features, f'APO_CRSWIR_{config}.tif')).read()\n",
    "    amplitude_map_crswir, phase_map_crswir, offset_map_crswir = crswir_APO[0], crswir_APO[1], crswir_APO[2]\n",
    "    dem = rasterio.open(os.path.join(path_features, 'elevation_aspect.tif')).read()\n",
    "    elevation, aspect = dem[0], dem[1]\n",
    "\n",
    "    features = {\n",
    "        'amplitude_red': amplitude_map_r.ravel(),\n",
    "        'phase_red': phase_map_r.ravel(),\n",
    "        'offset_red': offset_map_r.ravel(),\n",
    "        'amplitude_green': amplitude_map_g.ravel(),\n",
    "        'phase_green': phase_map_g.ravel(),\n",
    "        'offset_green': offset_map_g.ravel(),\n",
    "        'amplitude_blue': amplitude_map_b.ravel(),\n",
    "        'phase_blue': phase_map_b.ravel(),\n",
    "        'offset_blue': offset_map_b.ravel(),\n",
    "        'amplitude_crswir': amplitude_map_crswir.ravel(),\n",
    "        'phase_crswir': phase_map_crswir.ravel(),\n",
    "        'offset_crswir': offset_map_crswir.ravel(),\n",
    "        'elevation': elevation.ravel(),\n",
    "        'aspect': aspect.ravel(),\n",
    "        'tile_id': np.array([tile_id] * aspect.size)  # Add tile_id to the features\n",
    "    }\n",
    "\n",
    "    path_reference = os.path.join(path, 'reference_species')\n",
    "    tif = [x for x in os.listdir(path_reference) if x.endswith('.tif')]\n",
    "    reference = rasterio.open(os.path.join(path_reference, tif[0])).read()\n",
    "    genus = reference[1]\n",
    "    phen = reference[2]  # Assuming phenology data is stored in the third band\n",
    "    source = reference[4]\n",
    "    valid_mask = (forest_mask & (phen != 0)).astype(bool)\n",
    "\n",
    "    filtered_features = {k: v[valid_mask.ravel()] for k, v in features.items()}\n",
    "    filtered_weights = weights[valid_mask.ravel()]\n",
    "    filtered_genus = genus[valid_mask]\n",
    "    filtered_phen = phen[valid_mask]\n",
    "    filtered_source = source[valid_mask]\n",
    "\n",
    "    filtered_features['genus'] = filtered_genus\n",
    "    filtered_features['phen'] = filtered_phen\n",
    "    filtered_features['source'] = filtered_source\n",
    "\n",
    "    df = pd.DataFrame(filtered_features)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df, filtered_weights[df.index]\n",
    "\n",
    "def load_data(directory: str, config: str) -> pd.DataFrame:\n",
    "    all_data = []\n",
    "    all_weights = []\n",
    "    tile_to_greco = {}\n",
    "\n",
    "    for folder in tqdm(os.listdir(directory)):\n",
    "        path = os.path.join(directory, folder)\n",
    "        if folder.__contains__('.DS_Store') or folder.__contains__('.txt'):\n",
    "            continue\n",
    "        try:\n",
    "            tile_df, tile_weight = load_data_from_tile(path, config)\n",
    "            tile_id = os.path.basename(path).split('_')[1]\n",
    "            greco_region = \"_\".join(os.path.basename(path).split('_')[4:-1])\n",
    "            tile_to_greco[tile_id] = greco_region\n",
    "            tile_df['tile_id'] = tile_id\n",
    "            all_data.append(tile_df)\n",
    "            all_weights.append(tile_weight)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Loaded {len(all_data)} tiles\")\n",
    "    data_df = pd.concat(all_data, ignore_index=True)\n",
    "    weights_array = np.concatenate(all_weights)\n",
    "\n",
    "    return data_df, weights_array, tile_to_greco\n",
    "\n",
    "# # Load data\n",
    "# data_dir = '/Users/arthurcalvi/Data/species/validation/tiles'\n",
    "# data, all_weights, tile_to_greco = load_data(data_dir)\n",
    "\n",
    "# # Verify data structure\n",
    "# print(data.head())\n",
    "# print(tile_to_greco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from collections import Counter\n",
    "from utils import mapping_real_greco\n",
    "# Split data into training and validation sets\n",
    "def stratified_group_split(data, test_size=0.25, random_state=42):\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    split = splitter.split(data, groups=data['tile_id'])\n",
    "    train_idx, val_idx = next(split)\n",
    "    \n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# Verify the split\n",
    "def verify_split(train_data, val_data):\n",
    "    # Check distribution of phenology classes\n",
    "    train_phen_counts = Counter(train_data['phen'])\n",
    "    val_phen_counts = Counter(val_data['phen'])\n",
    "    \n",
    "    print(\"Training phenology class distribution:\", train_phen_counts)\n",
    "    print(\"Validation phenology class distribution:\", val_phen_counts)\n",
    "    \n",
    "    # Check distribution of GRECO regions\n",
    "    train_greco_counts = Counter(train_data['greco_region'])\n",
    "    val_greco_counts = Counter(val_data['greco_region'])\n",
    "    \n",
    "    print(\"Training GRECO region distribution:\", train_greco_counts)\n",
    "    print(\"Validation GRECO region distribution:\", val_greco_counts)\n",
    "    \n",
    "    # Ensure no overlap of tiles between training and validation\n",
    "    train_tiles = set(train_data['tile_id'])\n",
    "    val_tiles = set(val_data['tile_id'])\n",
    "    \n",
    "    print(\"Common tiles between training and validation:\", train_tiles.intersection(val_tiles))\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_table = pd.DataFrame(columns=['GRECO Region', 'Set', 'Deciduous', 'Evergreen', 'Total'])\n",
    "    \n",
    "    for greco_region in set(train_data['greco_region']).union(set(val_data['greco_region'])):\n",
    "        train_deciduous = len(train_data[(train_data['greco_region'] == greco_region) & (train_data['phen'] == 1)])\n",
    "        train_evergreen = len(train_data[(train_data['greco_region'] == greco_region) & (train_data['phen'] == 2)])\n",
    "        val_deciduous = len(val_data[(val_data['greco_region'] == greco_region) & (val_data['phen'] == 1)])\n",
    "        val_evergreen = len(val_data[(val_data['greco_region'] == greco_region) & (val_data['phen'] == 2)])\n",
    "        \n",
    "        summary_table = summary_table.append({\n",
    "            'GRECO Region': greco_region,\n",
    "            'Set': 'Training',\n",
    "            'Deciduous': train_deciduous,\n",
    "            'Evergreen': train_evergreen,\n",
    "            'Total': train_deciduous + train_evergreen\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        summary_table = summary_table.append({\n",
    "            'GRECO Region': greco_region,\n",
    "            'Set': 'Validation',\n",
    "            'Deciduous': val_deciduous,\n",
    "            'Evergreen': val_evergreen,\n",
    "            'Total': val_deciduous + val_evergreen\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    # Add total row\n",
    "    total_deciduous_train = summary_table[summary_table['Set'] == 'Training']['Deciduous'].sum()\n",
    "    total_evergreen_train = summary_table[summary_table['Set'] == 'Training']['Evergreen'].sum()\n",
    "    total_deciduous_val = summary_table[summary_table['Set'] == 'Validation']['Deciduous'].sum()\n",
    "    total_evergreen_val = summary_table[summary_table['Set'] == 'Validation']['Evergreen'].sum()\n",
    "    \n",
    "    summary_table = summary_table.append({\n",
    "        'GRECO Region': 'Total',\n",
    "        'Set': 'Training',\n",
    "        'Deciduous': total_deciduous_train,\n",
    "        'Evergreen': total_evergreen_train,\n",
    "        'Total': total_deciduous_train + total_evergreen_train\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    summary_table = summary_table.append({\n",
    "        'GRECO Region': 'Total',\n",
    "        'Set': 'Validation',\n",
    "        'Deciduous': total_deciduous_val,\n",
    "        'Evergreen': total_evergreen_val,\n",
    "        'Total': total_deciduous_val + total_evergreen_val\n",
    "    }, ignore_index=True)\n",
    "\n",
    "\n",
    "    summary_table['GRECO Region'] = summary_table['GRECO Region'].map(mapping_real_greco)\n",
    "    \n",
    "    print(summary_table)\n",
    "    \n",
    "    return summary_table\n",
    "\n",
    "methods = [\"resampled_no_weights\",\n",
    "            \"no_resample_no_weights\", \n",
    "            \"no_resample_cloud_weights\",\n",
    "            \"no_resample_cloud_disturbance_weights\"]\n",
    "\n",
    "years = [1, 2, 3]\n",
    "#combine methods and years to get all configs\n",
    "configs = [f\"{method}_Y{year}\" for method in methods for year in years]\n",
    "\n",
    "# Assuming data, all_weights, and tile_to_greco are already loaded from the provided code\n",
    "data_dir = '/Users/arthurcalvi/Data/species/validation/tiles'\n",
    "for config in tqdm(configs): \n",
    "    print(f'config : {config}')\n",
    "    data, all_weights, tile_to_greco = load_data(data_dir, config)\n",
    "    # Add GRECO region to the data\n",
    "    data['greco_region'] = data['tile_id'].map(tile_to_greco)\n",
    "\n",
    "    train_data, val_data = stratified_group_split(data)\n",
    "\n",
    "    # Verify the split\n",
    "    summary_table = verify_split(train_data, val_data)\n",
    "    summary_table.to_csv(f'summary_table_{config}.csv', index=False)\n",
    "    # Save the datasets\n",
    "    train_data.to_csv(f'train_data_{config}.csv', index=False)\n",
    "    val_data.to_csv(f'val_data_{config}.csv', index=False)\n",
    "\n",
    "    print(\"Training and validation datasets saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kayrros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
