{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "def fit_periodic_function_with_harmonics_robust(time_series: np.ndarray, qa: np.ndarray, dates: List[datetime], num_harmonics: int = 3, max_iter: int = 5, delta: float = 1.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fits a periodic function with up to three harmonics to a 3D time series data, \n",
    "    weighted by a quality assessment array using the provided dates. Uses iterative reweighted least squares \n",
    "    for robust fitting to handle outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    - time_series: np.ndarray, shape (time, width, height), the RGB channel data.\n",
    "    - qa: np.ndarray, shape (time, width, height), quality assessment data with values between 0 and 1.\n",
    "    - dates: List[datetime.datetime], dates corresponding to the time series data points.\n",
    "    - num_harmonics: int, number of harmonics to include in the model (1 to 3).\n",
    "    - max_iter: int, maximum number of iterations for IRLS.\n",
    "    - delta: float, parameter for robust loss function (Huber delta).\n",
    "    \n",
    "    Returns:\n",
    "    - amplitude_maps: List[np.ndarray], list of amplitude maps for each harmonic.\n",
    "    - phase_maps: List[np.ndarray], list of phase maps for each harmonic.\n",
    "    - offset_map: np.ndarray, constant offset of the fitted function.\n",
    "    - mae_map: np.ndarray, Mean Absolute Error of the fitted function.\n",
    "    - residuals_map: np.ndarray, residuals of the fitted function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert dates to 'datetime64' and compute normalized time as fraction of year\n",
    "    times_datetime64 = np.array(dates, dtype='datetime64[D]')\n",
    "    start_date = times_datetime64[0]\n",
    "    days_since_start = (times_datetime64 - start_date).astype(int)\n",
    "    t_normalized = days_since_start / 365.25  # Normalize to fraction of year\n",
    "\n",
    "    # Initial design matrix with harmonics and constant term\n",
    "    harmonics = []\n",
    "    for k in range(1, num_harmonics + 1):\n",
    "        t_radians = 2 * np.pi * k * t_normalized\n",
    "        harmonics.extend([np.cos(t_radians), np.sin(t_radians)])\n",
    "\n",
    "    A = np.stack(harmonics + [np.ones_like(t_normalized)], axis=-1)  # Design matrix\n",
    "\n",
    "    # Reshape time_series and qa for vectorized operations\n",
    "    pixels = time_series.reshape(time_series.shape[0], -1)\n",
    "    weights = qa.reshape(qa.shape[0], -1)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # Broadcasting for weighted design matrix\n",
    "        A_expanded = np.expand_dims(A, 2)\n",
    "        weights_expanded = np.expand_dims(weights, 1)\n",
    "        A_weighted = A_expanded * weights_expanded\n",
    "\n",
    "        # Compute the normal equation components\n",
    "        ATA = np.einsum('ijk,ilk->jlk', A_weighted, A_expanded)\n",
    "        ATb = np.einsum('ijk,ik->jk', A_weighted, pixels)\n",
    "\n",
    "        # Solve for parameters\n",
    "        ATA_reshaped = ATA.transpose(2, 0, 1)\n",
    "        ATb_reshaped = ATb.T\n",
    "        params = np.array([solve_params(ATA_reshaped[i], ATb_reshaped[i]) for i in range(ATA_reshaped.shape[0])])\n",
    "        num_params = 2 * num_harmonics + 1\n",
    "        params_reshaped = params.reshape(time_series.shape[1], time_series.shape[2], num_params).transpose(2, 0, 1)\n",
    "\n",
    "        # Calculate fitted values and residuals\n",
    "        fitted_values = np.dot(A, params.T)  # Shape: (time, n_pixels)\n",
    "        residuals = pixels - fitted_values\n",
    "\n",
    "        # Update weights based on residuals using Huber loss\n",
    "        residuals_abs = np.abs(residuals)\n",
    "        new_weights = np.where(residuals_abs < delta, \n",
    "                               1, \n",
    "                               delta / residuals_abs)\n",
    "        weights = np.minimum(weights, new_weights)\n",
    "\n",
    "    # Extract amplitude and phase maps\n",
    "    amplitude_maps = []\n",
    "    phase_maps = []\n",
    "\n",
    "    for i in range(num_harmonics):\n",
    "        A_params = params_reshaped[2 * i]\n",
    "        B_params = params_reshaped[2 * i + 1]\n",
    "        amplitude_map = np.sqrt(A_params**2 + B_params**2)\n",
    "        phase_map = np.arctan2(B_params, A_params)\n",
    "\n",
    "        # Adjust and normalize phases\n",
    "        phase_adjusted = (phase_map - (2 * np.pi * (i + 1) * t_normalized[0])) % (2 * np.pi)\n",
    "        phase_normalized = np.where(phase_adjusted > np.pi, phase_adjusted - 2 * np.pi, phase_adjusted)\n",
    "\n",
    "        amplitude_maps.append(amplitude_map.reshape(time_series.shape[1], time_series.shape[2]))\n",
    "        phase_maps.append(phase_normalized.reshape(time_series.shape[1], time_series.shape[2]))\n",
    "\n",
    "    # Offset map\n",
    "    offset_map = params_reshaped[-1].reshape(time_series.shape[1], time_series.shape[2])\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    mae = np.mean(np.abs(residuals), axis=0)\n",
    "    mae_map = mae.reshape(time_series.shape[1], time_series.shape[2])\n",
    "\n",
    "    # Reshape residuals to match original dimensions\n",
    "    residuals_map = residuals.reshape(time_series.shape[0], time_series.shape[1], time_series.shape[2])\n",
    "\n",
    "    return (*amplitude_maps, *phase_maps, offset_map, mae_map, residuals_map)\n",
    "\n",
    "def solve_params(ATA: np.ndarray, ATb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Solve linear equations with error handling for non-invertible cases. \"\"\"\n",
    "    try:\n",
    "        return np.linalg.solve(ATA, ATb)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.full(ATb.shape, np.nan)  # Return NaN for non-invertible matrices\n",
    "\n",
    "\n",
    "inverse_dfunc = {\n",
    "    'rgb': lambda x: x / 65535 if x.dtype == np.uint16 else x,\n",
    "    'ndvi': lambda x: 2 * (x - 0.5),\n",
    "    'gndvi': lambda x: 2 * (x - 0.5),\n",
    "    'ndwi': lambda x: 2 * (x - 0.5),\n",
    "    'ndmi': lambda x: 2 * (x - 0.5),\n",
    "    'nbr': lambda x: 2 * (x - 0.5),\n",
    "    'ndre': lambda x: 2 * (x - 0.5),\n",
    "    'evi': lambda x: 2 * (x - 0.5) / 2.5,  # for EVI, apply the inverse of the entire transformation\n",
    "    'crswir': lambda x: x * 5,  # scale back crswir\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare both fitting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import rasterio\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from utils import load_folder, get_aspect, calculate_slope_with_dates, postprocess_cloud_mask, postprocess_qa_vegetation\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import zscore\n",
    "from typing import Dict, Tuple, List\n",
    "from datetime import datetime\n",
    "\n",
    "def detect_outliers_and_adjust_weights(data: np.ndarray, weights: np.ndarray, threshold: float = 3.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detects outliers based on z-scores and adjusts weights accordingly.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: np.ndarray, the data for which outliers need to be detected.\n",
    "    - threshold: float, z-score threshold for outlier detection.\n",
    "    \n",
    "    Returns:\n",
    "    - adjusted_weights: np.ndarray, weights adjusted to reduce influence of outliers.\n",
    "    \"\"\"\n",
    "    # Calculate z-scores for the data\n",
    "    z_scores = zscore(data, axis=0)\n",
    "    \n",
    "    # Identify outliers based on z-score threshold\n",
    "    is_outlier = np.abs(z_scores) > threshold\n",
    "    \n",
    "    # Reduce weight for outliers\n",
    "    weights[is_outlier] = 0.001\n",
    "    \n",
    "    return weights \n",
    "\n",
    "indices = ['rgb', 'crswir', 'ndvi', 'gndvi', 'evi', 'nbr']\n",
    "dir_ = '/Users/arthurcalvi/Data/species/validation/tiles_2_5_km'\n",
    "error_files = []\n",
    "folder = os.listdir(dir_)[3]\n",
    "path = os.path.join(dir_, folder)\n",
    "max_iter = 2\n",
    "\n",
    "if os.path.isdir(path):\n",
    "    if os.path.exists(os.path.join(path, 'features')):\n",
    "        print('Features already extracted.')\n",
    "    else:\n",
    "    # if True:\n",
    "        print(f'Processing {folder}...')\n",
    "        dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "        dates.sort()\n",
    "        dict_indices = {index: inverse_dfunc[index](load_folder(os.path.join(path, index))) for index in indices}\n",
    "\n",
    "        qa = load_folder(os.path.join(path, 'qa'))\n",
    "        vegetation_mask = load_folder(os.path.join(path, 'qa'), postprocess_qa_vegetation, {}).mean(axis=0)\n",
    "\n",
    "        dir_dem = os.path.join(path, 'dem.tif')\n",
    "        raster = rasterio.open(dir_dem)\n",
    "        dem = raster.read(1)\n",
    "        aspect = get_aspect(dem)\n",
    "\n",
    "        # Process QA mask\n",
    "        new_qa = []\n",
    "        for frame in tqdm(qa):\n",
    "            frame_ = np.zeros_like(frame)\n",
    "            mask = (frame == 1) | (frame == 3) | (frame == 6) | (frame == 8) | (frame == 9) | (frame == 10) | (frame == 11)\n",
    "            frame_[mask] = 1\n",
    "            frame_ = postprocess_cloud_mask(frame_, 5, 25)\n",
    "            new_qa.append(frame_)\n",
    "        qa_mask = np.array(new_qa)\n",
    "        qa_mask = 1 - qa_mask\n",
    "\n",
    "        # Calculate slopes for disturbance detection\n",
    "        K = 6\n",
    "        slopes = [calculate_slope_with_dates(dict_indices['rgb'][:, 0], dates, i, K) for i in tqdm(range(dict_indices['rgb'].shape[0]))]\n",
    "        slopes = np.array(slopes)\n",
    "        zero_mask = np.zeros_like(qa_mask[0], dtype=int)\n",
    "        expanded_mask_with_disturbances = qa_mask.copy()\n",
    "        for i in range(8, len(slopes)):\n",
    "            zero_mask[abs(slopes[i]) > 10] = 1\n",
    "            expanded_mask_with_disturbances[i, zero_mask.astype(bool)] = 0.001\n",
    "\n",
    "        # Detect outliers and adjust weights\n",
    "        weights = detect_outliers_and_adjust_weights(dict_indices['crswir'], expanded_mask_with_disturbances, 3.0) \n",
    "\n",
    "        # Fit periodic functions with two different methods\n",
    "        #1 harmonic \n",
    "        start_1 = time.time()\n",
    "        amplitude_map, phase_map, offset_map, mae_map, residuals_map = fit_periodic_function_with_harmonics_robust(dict_indices['crswir'], weights, dates, 1, max_iter)\n",
    "        end_1 = time.time()\n",
    "        print(f'Elapsed time for first method: {end_1 - start_1}')\n",
    "        #2 harmonics\n",
    "        start_2 = time.time()   \n",
    "        amplitude_map_21, amplitude_map_22, phase_map_21, phase_map_22, offset_map_2, mae_map_2, residuals_map_2 = fit_periodic_function_with_harmonics_robust(dict_indices['crswir'], weights, dates, 2, max_iter)\n",
    "        end_2 = time.time()\n",
    "        print(f'Elapsed time for second method: {end_2 - start_2}')\n",
    "        #3 harmonics\n",
    "        start_3 = time.time()\n",
    "        amplitude_map_31, amplitude_map_32, amplitude_map_33, phase_map_31, phase_map_32, phase_map_33, offset_map_3, mae_map_3, residuals_map_3 = fit_periodic_function_with_harmonics_robust(dict_indices['crswir'], weights, dates, 3, max_iter)\n",
    "        end_3 = time.time()\n",
    "        print(f'Elapsed time for third method: {end_3 - start_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import normalize\n",
    "#show the 7 maps created on two different rows (one row = one method)\n",
    "fig, axs = plt.subplots(3, 8, figsize=(20, 10))\n",
    "\n",
    "im = axs[0, 0].imshow(amplitude_map, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[0, 0].set_title('Amplitude 1')\n",
    "#add colorbar shrink = 0.5 horizontal \n",
    "fig.colorbar(im, ax=axs[0, 0], orientation='horizontal', shrink=0.5)\n",
    "im = axs[0, 1].imshow(phase_map, cmap='viridis')\n",
    "axs[0, 1].set_title('Phase 1')\n",
    "fig.colorbar(im, ax=axs[0, 1], orientation='horizontal', shrink=0.5)\n",
    "im = axs[0, 2].imshow(offset_map, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[0, 2].set_title('Offset 2')\n",
    "fig.colorbar(im, ax=axs[0, 2], orientation='horizontal', shrink=0.5)\n",
    "im = axs[0, 3].imshow(mae_map, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[0, 3].set_title('Sigma 2')\n",
    "fig.colorbar(im, ax=axs[0, 3], orientation='horizontal', shrink=0.5)\n",
    "axs[0, 4].imshow(2 * normalize(dict_indices['rgb'][-1].transpose(1, 2, 0)))\n",
    "axs[0, 4].set_title('RGB')\n",
    "im = axs[0, 5].imshow(aspect, cmap='viridis')\n",
    "axs[0, 5].set_title('Aspect')\n",
    "fig.colorbar(im, ax=axs[0, 5], orientation='horizontal', shrink=0.5)\n",
    "\n",
    "im = axs[1, 0].imshow(amplitude_map_21, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[1, 0].set_title('Amplitude 21')\n",
    "fig.colorbar(im, ax=axs[1, 0], orientation='horizontal', shrink=0.5)\n",
    "im = axs[1, 1].imshow(phase_map_21, cmap='viridis')\n",
    "axs[1, 1].set_title('Phase 21')\n",
    "fig.colorbar(im, ax=axs[1, 1], orientation='horizontal', shrink=0.5)\n",
    "im = axs[1, 2].imshow(offset_map_2, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[1, 2].set_title('Offset 2')\n",
    "fig.colorbar(im, ax=axs[1, 2], orientation='horizontal', shrink=0.5)\n",
    "im = axs[1, 3].imshow(mae_map_2, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[1, 3].set_title('Sigma 2')\n",
    "fig.colorbar(im, ax=axs[1, 3], orientation='horizontal', shrink=0.5)\n",
    "axs[1, 4].imshow(amplitude_map_22, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[1, 4].set_title('Amplitude 22')\n",
    "fig.colorbar(im, ax=axs[1, 4], orientation='horizontal', shrink=0.5)\n",
    "im = axs[1, 5].imshow(phase_map_22, cmap='viridis')\n",
    "axs[1, 5].set_title('Phase 22')\n",
    "fig.colorbar(im, ax=axs[1, 5], orientation='horizontal', shrink=0.5)\n",
    "\n",
    "im = axs[2, 0].imshow(amplitude_map_31, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[2, 0].set_title('Amplitude 31')\n",
    "fig.colorbar(im, ax=axs[2, 0], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 1].imshow(phase_map_31, cmap='viridis')\n",
    "axs[2, 1].set_title('Phase 31')\n",
    "fig.colorbar(im, ax=axs[2, 1], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 2].imshow(offset_map_3, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[2, 2].set_title('Offset 3')\n",
    "fig.colorbar(im, ax=axs[2, 2], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 3].imshow(mae_map_3, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[2, 3].set_title('Sigma 3')\n",
    "fig.colorbar(im, ax=axs[2, 3], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 4].imshow(amplitude_map_32, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[2, 4].set_title('Amplitude 32')\n",
    "fig.colorbar(im, ax=axs[2, 4], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 5].imshow(phase_map_32, cmap='viridis')\n",
    "axs[2, 5].set_title('Phase 32')\n",
    "fig.colorbar(im, ax=axs[2, 5], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 6].imshow(amplitude_map_33, cmap='viridis', vmin=0, vmax=65535)\n",
    "axs[2, 6].set_title('Amplitude 33')\n",
    "fig.colorbar(im, ax=axs[2, 6], orientation='horizontal', shrink=0.5)\n",
    "im = axs[2, 7].imshow(phase_map_33, cmap='viridis')\n",
    "axs[2, 7].set_title('Phase 33')\n",
    "fig.colorbar(im, ax=axs[2, 7], orientation='horizontal', shrink=0.5)\n",
    "\n",
    "for ax in axs:\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'1 harmonic - mae mean = {mae_map.mean()}, mae std = {mae_map.std()}')\n",
    "print(f'2 harmonics - mae mean = {mae_map_2.mean()}, mae std = {mae_map_2.std()}')\n",
    "print(f'3 harmonics - mae mean = {mae_map_3.mean()}, mae std = {mae_map_3.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the forest mask\n",
    "\n",
    "vegetation_mask > 0.25 semble etre une bonne valeur pour la foret sans enlever trop pixels de foret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load forest \n",
    "\n",
    "path_CHM = '/Users/arthurcalvi/Data/Disturbances_maps/FORMS/int2/2020_l93.tif'\n",
    "chm2020 = rasterio.open(path_CHM) #cm \n",
    "# array = chm2020.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import transform_bounds, reproject, Resampling\n",
    "from rasterio.windows import from_bounds\n",
    "import numpy as np\n",
    "\n",
    "def extract_and_reproject_window(big_raster: rasterio.io.DatasetReader, \n",
    "                                 small_raster: rasterio.io.DatasetReader):\n",
    "    \"\"\"\n",
    "    Extract a window from the big raster within the bounds of the small raster and reproject it \n",
    "    to the CRS of the small raster.\n",
    "\n",
    "    Args:\n",
    "        big_raster (rasterio.io.DatasetReader): The large raster (e.g., chm2020) already opened with rasterio.\n",
    "        small_raster (rasterio.io.DatasetReader): The small raster already opened with rasterio.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The reprojected windowed data.\n",
    "        rasterio.Affine: The transform of the reprojected data.\n",
    "    \"\"\"\n",
    "    # Get the bounds and CRS of the small raster\n",
    "    small_bounds = small_raster.bounds\n",
    "    small_crs = small_raster.crs\n",
    "\n",
    "    # Reproject the bounds of the small raster to the CRS of the big raster\n",
    "    reprojected_bounds = transform_bounds(small_crs, big_raster.crs, *small_bounds)\n",
    "\n",
    "    # Create a window from the reprojected bounds\n",
    "    window = from_bounds(*reprojected_bounds, transform=big_raster.transform)\n",
    "\n",
    "    # Read the data within this window\n",
    "    windowed_data = big_raster.read(window=window)\n",
    "    window_transform = big_raster.window_transform(window)\n",
    "\n",
    "    # Prepare an array to hold the reprojected data\n",
    "    reprojected_data = np.empty(shape=(big_raster.count, \n",
    "                                       small_raster.height, \n",
    "                                       small_raster.width), dtype=windowed_data.dtype)\n",
    "\n",
    "    # Reproject the windowed data to the CRS of the small raster\n",
    "    reproject(\n",
    "        source=windowed_data,\n",
    "        destination=reprojected_data,\n",
    "        src_transform=window_transform,\n",
    "        src_crs=big_raster.crs,\n",
    "        dst_transform=small_raster.transform,\n",
    "        dst_crs=small_crs,\n",
    "        resampling=Resampling.nearest \n",
    "\n",
    "    )\n",
    "\n",
    "    mask = (reprojected_data > 10_000) & (reprojected_data < 35_000)\n",
    "    reprojected_data[mask] = reprojected_data.mean()\n",
    "\n",
    "    return reprojected_data, small_raster.transform\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chm2020_cropped, transform = extract_and_reproject_window(chm2020, raster)\n",
    "\n",
    "#Build forest mask \n",
    "vegetation_mask = (vegetation_mask > 0.25).astype(bool)\n",
    "mask = (chm2020_cropped > 500) & vegetation_mask \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(3 * normalize(dict_indices['rgb'][-1].transpose(1, 2, 0)))\n",
    "axes[0].set_title('RGB')\n",
    "axes[1].imshow(mask.squeeze(), cmap='viridis')\n",
    "axes[1].set_title('Forest mask')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "def reconstruct_signal(amplitudes: List[np.ndarray], phases: List[np.ndarray], offset_map: np.ndarray, dates: List[datetime], pixel_coords: Tuple[int, int]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstructs the time series signal for a specific pixel using the fitted parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - amplitudes: List[np.ndarray], list of amplitude maps for each harmonic.\n",
    "    - phases: List[np.ndarray], list of phase maps for each harmonic.\n",
    "    - offset_map: np.ndarray, constant offset of the fitted function.\n",
    "    - dates: List[datetime.datetime], dates corresponding to the time series data points.\n",
    "    - pixel_coords: Tuple[int, int], (x, y) coordinates of the pixel in the image.\n",
    "    \n",
    "    Returns:\n",
    "    - reconstructed_signal: np.ndarray, the reconstructed signal for the specified pixel.\n",
    "    - times_datetime64: np.ndarray, the dates corresponding to the time series data points.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert dates to 'datetime64' and compute normalized time as fraction of year\n",
    "    times_datetime64 = np.array(dates, dtype='datetime64[D]')\n",
    "    # Create times_datetime64 with regular time step every week\n",
    "    times_datetime64 = np.arange(times_datetime64[0], times_datetime64[-1] + np.timedelta64(7, 'D'), np.timedelta64(7, 'D'))\n",
    "    start_date = times_datetime64[0]\n",
    "    days_since_start = (times_datetime64 - start_date).astype(int)\n",
    "    t_normalized = days_since_start / 365.25  # Normalize to fraction of year\n",
    "\n",
    "    # Initialize the signal with the offset\n",
    "    signal = offset_map[pixel_coords[0], pixel_coords[1]] * np.ones_like(t_normalized)\n",
    "\n",
    "    # Add harmonics to the signal\n",
    "    for i, (amp_map, phase_map) in enumerate(zip(amplitudes, phases)):\n",
    "        # Convert normalized time to radians for this harmonic\n",
    "        t_radians = 2 * np.pi * (i + 1) * t_normalized\n",
    "        A = amp_map[pixel_coords[0], pixel_coords[1]] * np.cos(phase_map[pixel_coords[0], pixel_coords[1]])\n",
    "        B = amp_map[pixel_coords[0], pixel_coords[1]] * np.sin(phase_map[pixel_coords[0], pixel_coords[1]])\n",
    "        \n",
    "        signal += A * np.cos(t_radians) + B * np.sin(t_radians)\n",
    "\n",
    "    return signal, times_datetime64\n",
    "\n",
    "pixel = (50, 10)\n",
    "signal1, time = reconstruct_signal([amplitude_map], [phase_map], offset_map, dates, pixel)\n",
    "signal2, _ = reconstruct_signal([amplitude_map_21, amplitude_map_22], [phase_map_21, phase_map_22], offset_map_2, dates, pixel)\n",
    "signal3, _ = reconstruct_signal([amplitude_map_31, amplitude_map_32, amplitude_map_33], [phase_map_31, phase_map_32, phase_map_33], offset_map_3, dates, pixel)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(20, 10))\n",
    "\n",
    "ax[0].plot(time, signal1, label='Method 1')\n",
    "ax[0].set_title('Reconstructed signal using method 1')\n",
    "for i in range(len(dates)):\n",
    "    ax[0].scatter(dates[i], dict_indices['crswir'][i, pixel[0], pixel[1]], color=(0,0,0, expanded_mask_with_disturbances[i, pixel[0], pixel[1]]))\n",
    "text = f'A1 = {amplitude_map[pixel[0], pixel[1]]:.2f}, P1 = {phase_map[pixel[0], pixel[1]]:.2f}, C = {offset_map[pixel[0], pixel[1]]:.2f}'\n",
    "ax[0].text(0.5, 0.9, text, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes)\n",
    "\n",
    "#show residual\n",
    "\n",
    "ax[1].plot(time, signal2, label='Method 2')\n",
    "ax[1].set_title('Reconstructed signal using method 2')\n",
    "ax[1].scatter(dates, dict_indices['crswir'][:, pixel[0], pixel[1]], label='Original signal', color='k')\n",
    "text = f'A1 = {amplitude_map_21[pixel[0], pixel[1]]:.2f}, P1 = {phase_map_21[pixel[0], pixel[1]]:.2f}, A2 = {amplitude_map_22[pixel[0], pixel[1]]:.2f}, P2 = {phase_map_22[pixel[0], pixel[1]]:.2f}, C = {offset_map_2[pixel[0], pixel[1]]:.2f}'\n",
    "ax[1].text(0.5, 0.9, text, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes)\n",
    "\n",
    "ax[2].plot(time, signal3, label='Method 3')\n",
    "ax[2].set_title('Reconstructed signal using method 3')\n",
    "ax[2].scatter(dates, dict_indices['crswir'][:, pixel[0], pixel[1]], label='Original signal', color='k')\n",
    "text = f'A1 = {amplitude_map_31[pixel[0], pixel[1]]:.2f}, P1 = {phase_map_31[pixel[0], pixel[1]]:.2f}, A2 = {amplitude_map_32[pixel[0], pixel[1]]:.2f}, P2 = {phase_map_32[pixel[0], pixel[1]]:.2f}, A3 = {amplitude_map_33[pixel[0], pixel[1]]:.2f}, P3 = {phase_map_33[pixel[0], pixel[1]]:.2f}, C = {offset_map_3[pixel[0], pixel[1]]:.2f}'\n",
    "ax[2].text(0.5, 0.9, text, horizontalalignment='center', verticalalignment='center', transform=ax[2].transAxes)\n",
    "\n",
    "for a in ax:\n",
    "    a.legend()\n",
    "    a.grid()\n",
    "    a.spines['top'].set_visible(False)\n",
    "    a.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kayrros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
