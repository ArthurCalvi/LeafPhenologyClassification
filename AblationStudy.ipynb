{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study 1: LDA-Based Phenology Classification\n",
    "\n",
    "In this ablation study, we aimed to assess the impact of different configurations on the performance of an LDA-based phenology classification pipeline. We focused on the following configurations:\n",
    "1. Resampled data without weights\n",
    "2. No resampling and no weights\n",
    "3. No resampling with cloud weights\n",
    "4. No resampling with cloud disturbance weights\n",
    "\n",
    "We used the \"no_resample_cloud_disturbance_weights\" configuration to train our LDA model. This model was then applied consistently across all configurations to ensure a fair comparison. For each configuration, we computed the ROC curve and ROC-AUC score, identified the optimal threshold, and applied it to the validation set to predict phenology classes. Metrics were computed on the validation set and broken down by GRECO regions. The results highlighted the classification performance of each configuration through ROC curves and a bar chart showing the best F1 scores for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np \n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def train_and_evaluate_fold(model, X_train, y_train, X_test, y_test, regions_test, region_metrics):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "    }\n",
    "\n",
    "    for region in region_metrics.keys():\n",
    "        region_mask = (regions_test == region)\n",
    "        y_test_region = y_test[region_mask]\n",
    "        y_pred_region = pd.Series(y_pred, index=y_test.index)[region_mask]\n",
    "        if not y_test_region.empty:\n",
    "            region_metrics_values = {\n",
    "                'precision': precision_score(y_test_region, y_pred_region, average='weighted', zero_division=0),\n",
    "                'recall': recall_score(y_test_region, y_pred_region, average='weighted', zero_division=0),\n",
    "                'f1_score': f1_score(y_test_region, y_pred_region, average='weighted', zero_division=0),\n",
    "            }\n",
    "            region_metrics[region].append(region_metrics_values)\n",
    "    \n",
    "    return metrics, region_metrics\n",
    "\n",
    "def evaluate_model(model: BaseEstimator, X: pd.DataFrame, y: pd.Series, gkf: GroupKFold, groups, regions: pd.Series) -> (pd.DataFrame, dict):\n",
    "    \"\"\"\n",
    "    Evaluates a model using stratified k-fold cross-validation and returns the averaged metrics.\n",
    "    Also calculates the metrics per region.\n",
    "\n",
    "    Parameters:\n",
    "    model (BaseEstimator): The machine learning model to be evaluated.\n",
    "    X (pd.DataFrame): The feature matrix.\n",
    "    y (pd.Series): The target vector.\n",
    "    gkf (GroupKFold): The group k-fold cross-validator.\n",
    "    regions (pd.Series): The series indicating the region for each sample.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the averaged metrics across all folds.\n",
    "    dict: A dictionary with regions as keys and DataFrames of metrics as values.\n",
    "    \"\"\"\n",
    "    metrics_list = []\n",
    "    region_metrics = {region: [] for region in regions.unique()}\n",
    "    \n",
    "    results = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(train_and_evaluate_fold)(\n",
    "            model, X.iloc[train_index], y.iloc[train_index], X.iloc[test_index], y.iloc[test_index], regions.iloc[test_index], region_metrics\n",
    "        )\n",
    "        for train_index, test_index in gkf.split(X, y, groups)\n",
    "    )\n",
    "\n",
    "    for metrics, fold_region_metrics in results:\n",
    "        metrics_list.append(metrics)\n",
    "        for region in region_metrics.keys():\n",
    "            region_metrics[region].extend(fold_region_metrics[region])\n",
    "\n",
    "    # Average the metrics over all the folds\n",
    "    avg_metrics = {metric: np.mean([fold_metrics[metric] for fold_metrics in metrics_list]) for metric in metrics_list[0].keys()}\n",
    "    \n",
    "    print('Average metrics:', avg_metrics)\n",
    "    avg_region_metrics = {}\n",
    "    for region, region_metrics_list in region_metrics.items():\n",
    "        avg_region_metrics[region] = {metric: np.mean([region_metrics_values[metric] for region_metrics_values in region_metrics_list]) for metric in region_metrics_list[0].keys()}\n",
    "    \n",
    "    return pd.DataFrame([avg_metrics]), {region: pd.DataFrame([metrics]) for region, metrics in avg_region_metrics.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from utils import load_and_preprocess_table_data, load_checkpoint\n",
    "from warnings import filterwarnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "model_name = 'MLP_no_resample_cloud_disturbance_weights_3Y_Group'\n",
    "params = load_checkpoint(model_name, checkpoint_dir='checkpoints').best_params_\n",
    "model = MLPClassifier(**params)\n",
    "\n",
    "# Define the configurations for the ablation study\n",
    "configs = [\n",
    "    \"no_resample_cloud_disturbance_weights\",\n",
    "    \"no_resample_cloud_weights\",\n",
    "    \"no_resample_no_weights\",\n",
    "    \"resampled_no_weights\"\n",
    "]\n",
    "\n",
    "years = [1, 2, 3]\n",
    "\n",
    "# Define features and target\n",
    "features = ['amplitude_red', 'cos_phase_red','offset_red',\n",
    "            'cos_phase_blue', \n",
    "            'amplitude_crswir', 'cos_phase_crswir', 'sin_phase_crswir', 'offset_crswir', \n",
    "            'elevation']\n",
    "\n",
    "target = 'phen'\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "overall_metrics = {}\n",
    "greco_region_metrics = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Apply the trained RF model to all configurations\n",
    "for config in configs:\n",
    "    for year in years:\n",
    "        data = load_and_preprocess_table_data(config+f'_{year}Y')\n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "        # Adjust target labels to start from 0\n",
    "        y = y - 1\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = RobustScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Convert X_scaled back to DataFrame\n",
    "        X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "        regions = data['greco_region']\n",
    "        groups = data['tile_id']\n",
    "\n",
    "        # Compute metrics on the validation set\n",
    "        overall_report, region_reports = evaluate_model(model, X_scaled, y, gkf, groups,  regions)\n",
    "        overall_metrics[f\"{config}_{year}Y\"] = overall_report\n",
    "\n",
    "        for region, report in region_reports.items():\n",
    "            if f\"{config}_{year}Y\" not in greco_region_metrics:\n",
    "                greco_region_metrics[f\"{config}_{year}Y\"] = {}\n",
    "            greco_region_metrics[f\"{config}_{year}Y\"][region] = report\n",
    "\n",
    "# year = 3\n",
    "# for config in tqdm(configs[1:]):\n",
    "#     data = load_and_preprocess_table_data(config+f'_{year}Y')\n",
    "#     X = data[features]\n",
    "#     y = data[target]\n",
    "#     # Adjust target labels to start from 0\n",
    "#     y = y - 1\n",
    "\n",
    "#     # Standardize features\n",
    "#     scaler = RobustScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     # Convert X_scaled back to DataFrame\n",
    "#     X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "#     regions = data['greco_region']\n",
    "#     groups = data['tile_id']\n",
    "\n",
    "#     # Compute metrics on the validation set\n",
    "#     overall_report, region_reports = evaluate_model(model, X_scaled, y, gkf, groups,  regions)\n",
    "#     overall_metrics[f\"{config}_{year}Y\"] = overall_report\n",
    "\n",
    "#     for region, report in region_reports.items():\n",
    "#         if f\"{config}_{year}Y\" not in greco_region_metrics:\n",
    "#             greco_region_metrics[f\"{config}_{year}Y\"] = {}\n",
    "#         greco_region_metrics[f\"{config}_{year}Y\"][region] = report\n",
    "\n",
    "# Save overall metrics to CSV\n",
    "overall_metrics_df = pd.concat(overall_metrics, axis=1).transpose()\n",
    "overall_metrics_df.to_csv(f'results/ablation_study_overall_metrics_{model_name}.csv', index=True)\n",
    "print(\"Overall metrics saved.\")\n",
    "\n",
    "# Save GRECO region metrics to CSV\n",
    "combined_greco_metrics = []\n",
    "for config_year, regions in greco_region_metrics.items():\n",
    "    for region, df in regions.items():\n",
    "        df['config_year'] = config_year\n",
    "        df['region'] = region\n",
    "        combined_greco_metrics.append(df)\n",
    "\n",
    "combined_greco_metrics_df = pd.concat(combined_greco_metrics, axis=0)\n",
    "combined_greco_metrics_df.to_csv(f'results/ablation_study_greco_region_metrics_{model_name}.csv', index=True)\n",
    "print(\"GRECO region metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import mapping_real_greco\n",
    "\n",
    "# Load the combined_greco_metrics_df from the CSV file\n",
    "combined_greco_metrics_df = pd.read_csv(f'results/ablation_study_greco_region_metrics_{model_name}.csv', index_col=0)\n",
    "\n",
    "# Filter only F1-score metrics\n",
    "f1_score_df = combined_greco_metrics_df[['f1_score', 'config_year', 'region']]\n",
    "f1_score_df['region'] = f1_score_df['region'].map(mapping_real_greco)\n",
    "\n",
    "# Extract method and year from config_year\n",
    "f1_score_df['method'] = f1_score_df['config_year'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "f1_score_df['year'] = f1_score_df['config_year'].apply(lambda x: x.split('_')[-1])\n",
    "\n",
    "# Define a custom color palette showing the goodness of each method\n",
    "palette = {\n",
    "    \"no_resample_cloud_disturbance_weights\": \"#1f77b4\",  # Blue\n",
    "    \"no_resample_cloud_weights\": \"#2ca02c\",  # Green\n",
    "    \"no_resample_no_weights\": \"#ff7f0e\",  # Orange\n",
    "    \"resampled_no_weights\": \"#d62728\"  # Red\n",
    "}\n",
    "\n",
    "# Set the plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Get the unique regions\n",
    "regions = f1_score_df['region'].unique()\n",
    "\n",
    "# Create a figure and axes for each region in a 4x3 grid\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(10, 12), sharey=True)\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Plot each region\n",
    "for i, (ax, region) in enumerate(zip(axes, regions)):\n",
    "    region_data = f1_score_df[f1_score_df['region'] == region]\n",
    "    sns.barplot(x='year', y='f1_score', hue='method', data=region_data, ax=ax, palette=palette, alpha=0.75)\n",
    "    ax.set_title(f'{region}', fontsize=14)\n",
    "    ax.set_xticks([0, 1, 2])\n",
    "    ax.set_xticklabels(['1y', '2y', '3y'])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # Horizontal grid\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.75)\n",
    "\n",
    "    if i%3 == 0:\n",
    "        ax.set_ylabel('F1-Score')\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    if i >= 9:\n",
    "        ax.set_xlabel('Length of the Time Series')\n",
    "    else:\n",
    "        ax.set_xlabel('')\n",
    "    # Remove the legend\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "# Hide any unused subplots except the last one for the legend\n",
    "for i in range(len(regions), len(axes) - 1):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Use the last subplot for the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, [x.replace('_', ' ') for x in labels], loc='center', title='Method', frameon=False, ncol=4, bbox_to_anchor=(0.5, 0.04), fontsize=12)\n",
    "axes[-1].axis('off')  # Hide the axis\n",
    "\n",
    "# Adjust the layout to leave space for the legend\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "fig.savefig(f'results/ablation_study_greco_region_metrics_{model_name}.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import mapping_real_greco\n",
    "\n",
    "# Load the combined_greco_metrics_df from the CSV file\n",
    "overall_metrics_df = pd.read_csv(f'results/ablation_study_overall_metrics_{model_name}.csv', index_col=0).reset_index()\n",
    "cols = overall_metrics_df.columns\n",
    "f1_metrics = overall_metrics_df[overall_metrics_df[cols[1]] == 'f1_score'].reset_index()\n",
    "f1_metrics.rename(columns={cols[0]: 'config_year', cols[1]: 'metric', cols[2]: 'score'}, inplace=True)\n",
    "f1_metrics.drop(columns='level_0', inplace=True)\n",
    "# Extract method and year from config_year\n",
    "f1_metrics['method'] = f1_metrics['config_year'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "f1_metrics['year'] = f1_metrics['config_year'].apply(lambda x: x.split('_')[-1])\n",
    "\n",
    "# Create a figure and axes for each region in a 4x3 grid\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4), sharey=True)\n",
    "\n",
    "sns.barplot(x='year', y='score', hue='method', data=f1_metrics, ax=ax, palette=palette, alpha=0.75)\n",
    "ax.set_title(f'Overall', fontsize=14)\n",
    "ax.set_xticks([0, 1, 2])\n",
    "ax.set_xticklabels(['1y', '2y', '3y'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Horizontal grid\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.75)\n",
    "\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_xlabel('Length of the Time Series')\n",
    "\n",
    "ax.get_legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metrics[ f1_metrics['method'] == 'no_resample_cloud_disturbance_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metrics.groupby('year')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.887682 - 0.819943"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kayrros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
