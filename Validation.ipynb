{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation for different techniques :\n",
    "\n",
    "1. Threshold on the phase_crswir \n",
    "\n",
    "2. GMM on ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the genus mapping\n",
    "\n",
    "phen_mapping = {1: 'deciduous', 2: 'evergreen'}\n",
    "\n",
    "def save_results_as_tif(output_path: str, data: np.ndarray, reference_path: str):\n",
    "    \"\"\"Save clustering results as a .tif file.\"\"\"\n",
    "    rgb_path = os.path.join(reference_path, 'rgb')\n",
    "    rgb_file = [f for f in os.listdir(rgb_path) if f.endswith('.tif')][0]\n",
    "    rgb_path = os.path.join(rgb_path, rgb_file)\n",
    "    with rasterio.open(rgb_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=rasterio.uint8, count=1)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(data.astype(rasterio.uint8), 1)\n",
    "\n",
    "def load_data_from_tile(path: str) -> tuple:\n",
    "    \"\"\"Load and preprocess data from a tile.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the tile directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing preprocessed features, weights, forest mask, reference path, and tile shape.\n",
    "    \"\"\"\n",
    "    dates = [datetime.strptime(filename.split('_')[0], '%Y-%m-%d') for filename in os.listdir(os.path.join(path, 'rgb'))]\n",
    "    dates.sort()\n",
    "    rgb = load_folder(os.path.join(path, 'rgb'))\n",
    "    chm = rasterio.open(os.path.join(path, 'tree_map', 'CHM2020.tif')).read(1)\n",
    "    forest_mask = (chm > 250).astype(bool)\n",
    "    slope_map = calculate_slope_with_dates(rgb[:, 0], dates, len(rgb[:, 0]) / 2, len(rgb[:, 0])) / 100\n",
    "    weights = (1 - abs(slope_map.ravel())).clip(0, 1)\n",
    "\n",
    "    path_features = os.path.join(path, 'features')\n",
    "    r_APO = rasterio.open(os.path.join(path_features, 'r_APO.tif')).read()\n",
    "    amplitude_map_r, phase_map_r, offset_map_r = r_APO[0], r_APO[1], r_APO[2]\n",
    "    crswir_APO = rasterio.open(os.path.join(path_features, 'crswir_APO.tif')).read()\n",
    "    amplitude_map_crswir, phase_map_crswir, offset_map_crswir = crswir_APO[0], crswir_APO[1], crswir_APO[2]\n",
    "    rcc_APO = rasterio.open(os.path.join(path_features, 'rcc_APO.tif')).read()\n",
    "    amplitude_map_rcc, phase_map_rcc, offset_map_rcc = rcc_APO[0], rcc_APO[1], rcc_APO[2]\n",
    "    dem = rasterio.open(os.path.join(path_features, 'elevation_aspect.tif')).read()\n",
    "    elevation, aspect = dem[0], dem[1]\n",
    "\n",
    "    features = {\n",
    "        'amplitude_red': amplitude_map_r.ravel(),\n",
    "        'phase_red': phase_map_r.ravel(),\n",
    "        'offset_red': offset_map_r.ravel(),\n",
    "        'amplitude_crswir': amplitude_map_crswir.ravel(),\n",
    "        'phase_crswir': phase_map_crswir.ravel(),\n",
    "        'offset_crswir': offset_map_crswir.ravel(),\n",
    "        'amplitude_rcc': amplitude_map_rcc.ravel(),\n",
    "        'phase_rcc': phase_map_rcc.ravel(),\n",
    "        'offset_rcc': offset_map_rcc.ravel(),\n",
    "        'elevation': elevation.ravel(),\n",
    "        'aspect': aspect.ravel()\n",
    "    }\n",
    "\n",
    "    filtered_features = {k: v[forest_mask.ravel()] for k, v in features.items()}\n",
    "    filtered_weights = weights[forest_mask.ravel()]\n",
    "\n",
    "    # Load reference data\n",
    "    path_reference = os.path.join(path, 'reference_species')\n",
    "    tif = [x for x in os.listdir(path_reference) if x.endswith('.tif')]\n",
    "    reference = rasterio.open(os.path.join(path_reference, tif[0])).read()\n",
    "    genus = reference[1]\n",
    "    phen = reference[2]  # Assuming phenology data is stored in the third band\n",
    "    filtered_genus = genus[forest_mask]\n",
    "    filtered_phen = phen[forest_mask]\n",
    "\n",
    "    filtered_features['genus'] = filtered_genus\n",
    "    filtered_features['phen'] = filtered_phen\n",
    "\n",
    "    return filtered_features, filtered_weights, forest_mask, chm.shape\n",
    "\n",
    "def load_data(directory: str) -> tuple:\n",
    "    \"\"\"Load and preprocess data from all tiles in the directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing tile subdirectories.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing all features, weights, masks, shapes, and paths for each tile.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_weights = []\n",
    "    all_ref = []\n",
    "    tile_shapes = []\n",
    "\n",
    "    for folder in tqdm(os.listdir(directory)):\n",
    "        path = os.path.join(directory, folder)\n",
    "        if folder.endswith('training') or folder.__contains__('.DS_Store') or folder.__contains__('.txt'):\n",
    "            continue\n",
    "        try:\n",
    "            filtered_features, filtered_weights, forest_mask, tile_shape = load_data_from_tile(path)\n",
    "            all_features.append(pd.DataFrame(filtered_features))\n",
    "            all_weights.append(filtered_weights)\n",
    "            all_ref.append(filtered_features['phen'])\n",
    "            tile_shapes.append((path, forest_mask, tile_shape))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Stack all features, weights, and references\n",
    "    all_features_stacked = pd.concat(all_features, ignore_index=True)\n",
    "    all_weights_stacked = np.concatenate(all_weights)\n",
    "    all_ref_stacked = np.concatenate(all_ref)\n",
    "\n",
    "    return all_features_stacked, all_weights_stacked, all_ref_stacked, tile_shapes\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "data_dir = '/Users/arthurcalvi/Data/species/validation/tiles'\n",
    "all_features_stacked, all_weights_stacked, all_ref_stacked, tile_shapes = load_data(data_dir)\n",
    "\n",
    "# Preprocess data\n",
    "features = ['amplitude_red', 'phase_red', 'offset_red', 'amplitude_crswir', 'phase_crswir', 'offset_crswir', 'amplitude_rcc', 'phase_rcc', 'offset_rcc', 'elevation', 'aspect']\n",
    "X = all_features_stacked[features]\n",
    "y_phen = all_features_stacked['phen']\n",
    "\n",
    "# Replace infinite values with NaNs\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Handle NaNs by imputing with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Update X with imputed values\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_as_tif(output_path: str, data: np.ndarray, reference_path: str):\n",
    "    \"\"\"Save clustering results as a .tif file.\"\"\"\n",
    "    rgb_path = os.path.join(reference_path, 'rgb')\n",
    "    rgb_file = [f for f in os.listdir(rgb_path) if f.endswith('.tif')][0]\n",
    "    rgb_path = os.path.join(rgb_path, rgb_file)\n",
    "    with rasterio.open(rgb_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=rasterio.uint8, count=1)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(data.astype(rasterio.uint8), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Threshold on the phase_crswir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the genus mapping\n",
    "phen_mapping = {1: 'deciduous', 2: 'evergreen'}\n",
    "\n",
    "# Define thresholding \n",
    "feature = 'phase_crswir'\n",
    "threshold = 0.96\n",
    "print(f\"Using threshold: {threshold} for feature: {feature}\")\n",
    "\n",
    "#asign the phenology predidction 2 if feature is greater than the threshold\n",
    "phen_predictions = np.where(X[feature] > threshold, 2, 1)\n",
    "\n",
    "mask_valid = (all_ref_stacked != 0)\n",
    "\n",
    "#compute oa, kappa, and confusion matrix on where the mask is valid\n",
    "oa = accuracy_score(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "kappa = cohen_kappa_score(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "conf_matrix = confusion_matrix(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "conf_matrix = conf_matrix / conf_matrix.sum() \n",
    "\n",
    "print(f\"Overall Accuracy: {oa}\")\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "print(f\"TP: {conf_matrix[0, 0]}\")\n",
    "print(f\"FP: {conf_matrix[0, 1]}\")\n",
    "print(f\"FN: {conf_matrix[1, 0]}\")\n",
    "print(f\"TN: {conf_matrix[1, 1]}\")\n",
    "\n",
    "#save results in a json \n",
    "os.makedirs('results', exist_ok=True)\n",
    "results = {\n",
    "    'experience': f'1-phenology_thresholding_feature-{feature}_threshold-{threshold}',\n",
    "    'feature': feature,\n",
    "    'threshold': threshold,\n",
    "    'overall_accuracy': oa,\n",
    "    'kappa': kappa,\n",
    "    'tp': conf_matrix[0, 0],\n",
    "    'fp': conf_matrix[0, 1],\n",
    "    'fn': conf_matrix[1, 0],\n",
    "    'tn': conf_matrix[1, 1]\n",
    "}\n",
    "results_path = os.path.join('results', f\"results_feature-{feature}_threshold-{threshold}.json\")\n",
    "pd.Series(results).to_json(results_path)\n",
    "\n",
    "# plot confusion matrix in a clean and lean way in percentage with seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='.1%', cmap='Blues', cbar=False, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xticklabels(['Deciduous', 'Evergreen'])\n",
    "ax.set_yticklabels(['Deciduous', 'Evergreen'])\n",
    "plt.show()\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.savefig(f'images/confusion_matrix_feature-{feature}_threhsold-{threshold}.png', dpi=300)\n",
    "\n",
    "#writing features \n",
    "print(\"Writing features for each tile...\")\n",
    "cluster_maps = []\n",
    "index = 0\n",
    "for path, forest_mask, tile_shape in tqdm(tile_shapes):\n",
    "    cluster_map = np.full(tile_shape, 0)\n",
    "    n_points = forest_mask.ravel().sum()\n",
    "    cluster_map.ravel()[forest_mask.ravel()] = phen_predictions[index:index + n_points]\n",
    "    index += n_points\n",
    "    cluster_maps.append((path, cluster_map))\n",
    "\n",
    "    # Save results for each tile\n",
    "    result_dir = os.path.join(path, 'results')\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    output_path = os.path.join(result_dir, f\"feature-{feature}_threshold-{threshold}.tif\")\n",
    "    save_results_as_tif(output_path, cluster_map, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans with 2 clusters and then thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import load_folder, calculate_slope_with_dates\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the genus mapping\n",
    "phen_mapping = {1: 'deciduous', 2: 'evergreen'}\n",
    "\n",
    "# Define feature subset selection using RFE\n",
    "def select_features(X, y, num_features):\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model, n_features_to_select=num_features)\n",
    "    fit = rfe.fit(X, y)\n",
    "    selected_features = [features[i] for i in range(len(features)) if fit.support_[i]]\n",
    "    return selected_features\n",
    "\n",
    "# Classify clusters based on the average phase_crswir value\n",
    "def classify_clusters(X: np.ndarray, clusters: np.ndarray, threshold: float = 0.96) -> np.ndarray:\n",
    "    cluster_labels = np.zeros(clusters.shape)\n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_mask = clusters == cluster\n",
    "        mean_phase_crswir = np.mean(X[cluster_mask])\n",
    "        cluster_labels[cluster_mask] = 2 if mean_phase_crswir > threshold else 1\n",
    "    return cluster_labels\n",
    "\n",
    "# Placeholder for optimal feature subset and evaluation metric\n",
    "optimal_feature_subset = None\n",
    "max_accuracy = float('-inf')\n",
    "all_clusters = []\n",
    "\n",
    "print(\"Running feature subset selection and clustering...\")\n",
    "# Feature subset selection and clustering\n",
    "list_accuracy_scores = []\n",
    "list_subset_features = []\n",
    "for num_features in tqdm(range(1, len(features) + 1)):\n",
    "    selected_features = select_features(X_scaled, y_phen, num_features)\n",
    "    X_subset = X_scaled[:, [features.index(f) for f in selected_features]]\n",
    "\n",
    "    # Run MiniBatchKMeans clustering\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=2, random_state=42)\n",
    "    clusters = minibatch_kmeans.fit_predict(X_subset, sample_weight=all_weights_stacked)\n",
    "    all_clusters.append(clusters)\n",
    "\n",
    "    # Classify clusters using the average phase_crswir value\n",
    "    phen_predictions = classify_clusters(X['phase_crswir'], clusters)\n",
    "\n",
    "    # Evaluate using overall accuracy\n",
    "    valid_mask = (y_phen != 0)\n",
    "    oa = accuracy_score(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "    kappa = cohen_kappa_score(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "    conf_matrix = confusion_matrix(all_ref_stacked[mask_valid], phen_predictions[mask_valid])\n",
    "    conf_matrix = conf_matrix / conf_matrix.sum() \n",
    "    list_accuracy_scores.append(oa)\n",
    "    list_subset_features.append(selected_features)\n",
    "    if oa > max_accuracy:\n",
    "        max_accuracy = oa\n",
    "        optimal_feature_subset = selected_features\n",
    "\n",
    "    # Save results\n",
    "    results = {\n",
    "        'experience': f'1-phenology_thresholding_cluster-k2_features_selection-{selected_features}_num_features-{num_features}',\n",
    "        'feature_selection': 'RFE',\n",
    "        'features': selected_features,\n",
    "        'num_features': num_features,\n",
    "        'clusterinfo': '2-means',\n",
    "        'feature': 'phase_crswir',\n",
    "        'threshold': threshold,\n",
    "        'overall_accuracy': oa,\n",
    "        'kappa': kappa,\n",
    "        'tp': conf_matrix[0, 0],\n",
    "        'fp': conf_matrix[0, 1],\n",
    "        'fn': conf_matrix[1, 0],\n",
    "        'tn': conf_matrix[1, 1]\n",
    "    }\n",
    "    results_path = os.path.join('results', f\"results_features_selection-{selected_features}_num_features-{num_features}.json\")\n",
    "    pd.Series(results).to_json(results_path)\n",
    "    print(f\"Overall Accuracy: {oa}\")\n",
    "    print(f\"Cohen's Kappa: {kappa}\")\n",
    "    print(f\"TP: {conf_matrix[0, 0]}\")\n",
    "    print(f\"FP: {conf_matrix[0, 1]}\")\n",
    "    print(f\"FN: {conf_matrix[1, 0]}\")\n",
    "    print(f\"TN: {conf_matrix[1, 1]}\")\n",
    "\n",
    "    #writing features \n",
    "    print(\"Writing features for each tile...\")\n",
    "    cluster_maps = []\n",
    "    index = 0\n",
    "    for path, forest_mask, tile_shape in tqdm(tile_shapes):\n",
    "        cluster_map = np.full(tile_shape, 0)\n",
    "        n_points = forest_mask.ravel().sum()\n",
    "        cluster_map.ravel()[forest_mask.ravel()] = phen_predictions[index:index + n_points]\n",
    "        index += n_points\n",
    "        cluster_maps.append((path, cluster_map))\n",
    "\n",
    "        # Save results for each tile\n",
    "        result_dir = os.path.join(path, 'results')\n",
    "        os.makedirs(result_dir, exist_ok=True)\n",
    "        output_path = os.path.join(result_dir, f\"{'_'.join(selected_features)}_k2.tif\")\n",
    "        save_results_as_tif(output_path, cluster_map, path)\n",
    "\n",
    "# Compute ARI matrix \n",
    "num_feature_sets = len(all_clusters)\n",
    "ari_matrix = np.zeros((num_feature_sets, num_feature_sets))\n",
    "\n",
    "for i in range(num_feature_sets):\n",
    "    for j in range(num_feature_sets):\n",
    "        ari_matrix[i, j] = adjusted_rand_score(all_clusters[i], all_clusters[j])\n",
    "\n",
    "\n",
    "print(f\"Optimal Feature Subset: {optimal_feature_subset}\")\n",
    "print(f\"Maximum Overall Accuracy: {max_accuracy}\")\n",
    "\n",
    "# Visualization of ARI matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(ari_matrix, cmap='RdYlGn', interpolation='nearest')\n",
    "plt.title('ARI Matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Feature Set Index')\n",
    "plt.ylabel('Feature Set Index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization of Overall Accuracy vs Number of Features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1, len(features) + 1), list_accuracy_scores, marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('Overall Accuracy vs Number of Features')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Visualization of Feature Importance\n",
    "feature_importance = np.zeros(len(features))\n",
    "for selected_features in list_subset_features:\n",
    "    for feature in selected_features:\n",
    "        feature_importance[features.index(feature)] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(features, feature_importance)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Selection Frequency')\n",
    "plt.title('Feature Importance (Selection Frequency)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature selection completed and optimal feature subset selected.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kayrros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
